{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10580406,"sourceType":"datasetVersion","datasetId":6547855},{"sourceId":10580423,"sourceType":"datasetVersion","datasetId":6547867},{"sourceId":10580457,"sourceType":"datasetVersion","datasetId":6547892},{"sourceId":10637807,"sourceType":"datasetVersion","datasetId":6586425}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":24.766825,"end_time":"2025-02-07T22:31:53.452931","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-02-07T22:31:28.686106","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"3a61ca17","cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings('ignore')\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.872157,"end_time":"2025-02-07T22:31:31.766037","exception":false,"start_time":"2025-02-07T22:31:30.893880","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:33.703831Z","iopub.execute_input":"2025-03-03T10:42:33.704323Z","iopub.status.idle":"2025-03-03T10:42:34.163776Z","shell.execute_reply.started":"2025-03-03T10:42:33.704276Z","shell.execute_reply":"2025-03-03T10:42:34.162682Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ey-open-science-training-data/NY_Mesonet_Weather.xlsx\n/kaggle/input/ey-geographical-shape-kml/Building_Footprint.kml\n/kaggle/input/ey-geographical-shape-kml/BUILDING_view_-5453825549351750874/BUILDING.shp\n/kaggle/input/ey-geographical-shape-kml/BUILDING_view_-5453825549351750874/BUILDING.shx\n/kaggle/input/ey-geographical-shape-kml/BUILDING_view_-5453825549351750874/BUILDING.dbf\n/kaggle/input/ey-geographical-shape-kml/BUILDING_view_-5453825549351750874/BUILDING.shp.xml\n/kaggle/input/ey-geographical-shape-kml/BUILDING_view_-5453825549351750874/BUILDING.cpg\n/kaggle/input/ey-geographical-shape-kml/BUILDING_view_-5453825549351750874/BUILDING.prj\n/kaggle/input/uhi-index-data/Training_data_uhi_index_UHI2025-v2.csv\n/kaggle/input/test-df-ey-open-science/Submission_template_UHI2025-v2.csv\n","output_type":"stream"}],"execution_count":1},{"id":"bde3ef87","cell_type":"code","source":"weather_data = pd.read_excel('/kaggle/input/ey-open-science-training-data/NY_Mesonet_Weather.xlsx')\ntrain_df = pd.read_csv('/kaggle/input/uhi-index-data/Training_data_uhi_index_UHI2025-v2.csv')\ntest_df = pd.read_csv('/kaggle/input/test-df-ey-open-science/Submission_template_UHI2025-v2.csv')","metadata":{"papermill":{"duration":0.673319,"end_time":"2025-02-07T22:31:32.447168","exception":false,"start_time":"2025-02-07T22:31:31.773849","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:34.165065Z","iopub.execute_input":"2025-03-03T10:42:34.165562Z","iopub.status.idle":"2025-03-03T10:42:34.940665Z","shell.execute_reply.started":"2025-03-03T10:42:34.165535Z","shell.execute_reply":"2025-03-03T10:42:34.939536Z"}},"outputs":[],"execution_count":2},{"id":"5d207f71","cell_type":"code","source":"bronx_df = pd.read_excel('/kaggle/input/ey-open-science-training-data/NY_Mesonet_Weather.xlsx', sheet_name='Bronx')\nmanhattan_df = pd.read_excel('/kaggle/input/ey-open-science-training-data/NY_Mesonet_Weather.xlsx', sheet_name='Manhattan')","metadata":{"papermill":{"duration":0.148418,"end_time":"2025-02-07T22:31:32.602784","exception":false,"start_time":"2025-02-07T22:31:32.454366","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:34.943158Z","iopub.execute_input":"2025-03-03T10:42:34.943576Z","iopub.status.idle":"2025-03-03T10:42:35.052637Z","shell.execute_reply.started":"2025-03-03T10:42:34.943543Z","shell.execute_reply":"2025-03-03T10:42:35.051421Z"}},"outputs":[],"execution_count":3},{"id":"23fd1c0d","cell_type":"code","source":"bronx_df['Date / Time'] = pd.to_datetime(bronx_df['Date / Time'])\nbronx_filtered = bronx_df[(bronx_df['Date / Time'].dt.hour <= 13)]\nbronx_filtered","metadata":{"papermill":{"duration":0.043127,"end_time":"2025-02-07T22:31:32.653461","exception":false,"start_time":"2025-02-07T22:31:32.610334","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.054108Z","iopub.execute_input":"2025-03-03T10:42:35.054473Z","iopub.status.idle":"2025-03-03T10:42:35.098792Z","shell.execute_reply.started":"2025-03-03T10:42:35.054444Z","shell.execute_reply":"2025-03-03T10:42:35.097707Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"           Date / Time  Air Temp at Surface [degC]  \\\n0  2021-07-24 06:00:00                        19.3   \n1  2021-07-24 06:05:00                        19.4   \n2  2021-07-24 06:10:00                        19.3   \n3  2021-07-24 06:15:00                        19.4   \n4  2021-07-24 06:20:00                        19.4   \n..                 ...                         ...   \n91 2021-07-24 13:35:00                        26.9   \n92 2021-07-24 13:40:00                        26.8   \n93 2021-07-24 13:45:00                        27.4   \n94 2021-07-24 13:50:00                        27.4   \n95 2021-07-24 13:55:00                        27.0   \n\n    Relative Humidity [percent]  Avg Wind Speed [m/s]  \\\n0                          88.2                   0.8   \n1                          87.9                   0.8   \n2                          87.6                   0.7   \n3                          87.4                   0.5   \n4                          87.0                   0.2   \n..                          ...                   ...   \n91                         46.6                   1.4   \n92                         46.2                   2.8   \n93                         46.0                   2.9   \n94                         44.7                   3.2   \n95                         45.2                   2.3   \n\n    Wind Direction [degrees]  Solar Flux [W/m^2]  \n0                        335                  12  \n1                        329                  18  \n2                        321                  25  \n3                        307                  33  \n4                        301                  42  \n..                       ...                 ...  \n91                       110                 392  \n92                        82                 532  \n93                       104                 670  \n94                       102                 825  \n95                        65                 881  \n\n[96 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date / Time</th>\n      <th>Air Temp at Surface [degC]</th>\n      <th>Relative Humidity [percent]</th>\n      <th>Avg Wind Speed [m/s]</th>\n      <th>Wind Direction [degrees]</th>\n      <th>Solar Flux [W/m^2]</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-07-24 06:00:00</td>\n      <td>19.3</td>\n      <td>88.2</td>\n      <td>0.8</td>\n      <td>335</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-07-24 06:05:00</td>\n      <td>19.4</td>\n      <td>87.9</td>\n      <td>0.8</td>\n      <td>329</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-07-24 06:10:00</td>\n      <td>19.3</td>\n      <td>87.6</td>\n      <td>0.7</td>\n      <td>321</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-07-24 06:15:00</td>\n      <td>19.4</td>\n      <td>87.4</td>\n      <td>0.5</td>\n      <td>307</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-07-24 06:20:00</td>\n      <td>19.4</td>\n      <td>87.0</td>\n      <td>0.2</td>\n      <td>301</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>2021-07-24 13:35:00</td>\n      <td>26.9</td>\n      <td>46.6</td>\n      <td>1.4</td>\n      <td>110</td>\n      <td>392</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>2021-07-24 13:40:00</td>\n      <td>26.8</td>\n      <td>46.2</td>\n      <td>2.8</td>\n      <td>82</td>\n      <td>532</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>2021-07-24 13:45:00</td>\n      <td>27.4</td>\n      <td>46.0</td>\n      <td>2.9</td>\n      <td>104</td>\n      <td>670</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>2021-07-24 13:50:00</td>\n      <td>27.4</td>\n      <td>44.7</td>\n      <td>3.2</td>\n      <td>102</td>\n      <td>825</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>2021-07-24 13:55:00</td>\n      <td>27.0</td>\n      <td>45.2</td>\n      <td>2.3</td>\n      <td>65</td>\n      <td>881</td>\n    </tr>\n  </tbody>\n</table>\n<p>96 rows × 6 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"id":"cdd82bce","cell_type":"code","source":"bronx_column_names = {\n    bronx_df.columns[1]: 'surface_air_temp',\n    bronx_df.columns[2]: 'relative_humidity',\n    bronx_df.columns[3]: 'avg_wind_speed',\n    bronx_df.columns[4]: 'wind_direction',\n    bronx_df.columns[5]: 'solar_flux'\n}\nmanhattan_column_names = {\n    manhattan_df.columns[1]: 'surface_air_temp',\n    manhattan_df.columns[2]: 'relative_humidity',\n    manhattan_df.columns[3]: 'avg_wind_speed',\n    manhattan_df.columns[4]: 'wind_direction',\n    manhattan_df.columns[5]: 'solar_flux'\n}\nbronx_df.rename(columns=bronx_column_names, inplace=True)\nmanhattan_df.rename(columns=manhattan_column_names, inplace=True)","metadata":{"papermill":{"duration":0.01626,"end_time":"2025-02-07T22:31:32.677312","exception":false,"start_time":"2025-02-07T22:31:32.661052","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.099790Z","iopub.execute_input":"2025-03-03T10:42:35.100121Z","iopub.status.idle":"2025-03-03T10:42:35.106870Z","shell.execute_reply.started":"2025-03-03T10:42:35.100079Z","shell.execute_reply":"2025-03-03T10:42:35.105648Z"}},"outputs":[],"execution_count":5},{"id":"4f411fcf","cell_type":"code","source":"bronx_df.nunique()","metadata":{"papermill":{"duration":0.019685,"end_time":"2025-02-07T22:31:32.704647","exception":false,"start_time":"2025-02-07T22:31:32.684962","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.108185Z","iopub.execute_input":"2025-03-03T10:42:35.108626Z","iopub.status.idle":"2025-03-03T10:42:35.122939Z","shell.execute_reply.started":"2025-03-03T10:42:35.108594Z","shell.execute_reply":"2025-03-03T10:42:35.121447Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Date / Time          169\nsurface_air_temp      70\nrelative_humidity    112\navg_wind_speed        44\nwind_direction       113\nsolar_flux           158\ndtype: int64"},"metadata":{}}],"execution_count":6},{"id":"eeaac5aa","cell_type":"code","source":"manhattan_df.nunique()","metadata":{"papermill":{"duration":0.017658,"end_time":"2025-02-07T22:31:32.730313","exception":false,"start_time":"2025-02-07T22:31:32.712655","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.124148Z","iopub.execute_input":"2025-03-03T10:42:35.124521Z","iopub.status.idle":"2025-03-03T10:42:35.152966Z","shell.execute_reply.started":"2025-03-03T10:42:35.124492Z","shell.execute_reply":"2025-03-03T10:42:35.151382Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Date / Time          169\nsurface_air_temp      59\nrelative_humidity    104\navg_wind_speed        33\nwind_direction       119\nsolar_flux           159\ndtype: int64"},"metadata":{}}],"execution_count":7},{"id":"c73e91c4","cell_type":"code","source":"train_df['datetime'] = pd.to_datetime(train_df['datetime'])\ntrain_df['time'] = train_df['datetime'].dt.time","metadata":{"papermill":{"duration":0.021235,"end_time":"2025-02-07T22:31:32.759220","exception":false,"start_time":"2025-02-07T22:31:32.737985","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.154560Z","iopub.execute_input":"2025-03-03T10:42:35.155165Z","iopub.status.idle":"2025-03-03T10:42:35.184493Z","shell.execute_reply.started":"2025-03-03T10:42:35.155117Z","shell.execute_reply":"2025-03-03T10:42:35.183455Z"}},"outputs":[],"execution_count":8},{"id":"3d7461b0","cell_type":"code","source":"def time_compress(df):\n    # Convert the \"Date / Time\" column to datetime (if not already)\n    df[\"Date / Time\"] = pd.to_datetime(df[\"Date / Time\"])\n    \n    # Calculate decimal hours (include seconds if available)\n    df[\"time_hours\"] = (\n        df[\"Date / Time\"].dt.hour + \n        df[\"Date / Time\"].dt.minute / 60.0 + \n        df[\"Date / Time\"].dt.second / 3600.0\n    )\n    \n    # Normalize the original time range (6 to 20) to a 0-1 scale\n    df[\"normalized\"] = (df[\"time_hours\"] - 6) / (20 - 6)\n    \n    # Map the normalized values to the new time range (3 to 4)\n    df[\"new_time_hours\"] = 3 + df[\"normalized\"] * (4 - 3)\n    \n    # Create the new timestamp by normalizing the date (midnight) and adding the new time as a timedelta.\n    # We do NOT round here so we preserve the differences (i.e. 21.4 sec differences should stick)\n    df[\"Date / Time\"] = df[\"Date / Time\"].dt.normalize() + pd.to_timedelta(df[\"new_time_hours\"], unit=\"h\")\n    \n    # Drop the intermediate columns\n    df.drop(columns=[\"time_hours\", \"normalized\", \"new_time_hours\"], inplace=True)\n    \n    return df\n","metadata":{"papermill":{"duration":0.015372,"end_time":"2025-02-07T22:31:32.782324","exception":false,"start_time":"2025-02-07T22:31:32.766952","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.187943Z","iopub.execute_input":"2025-03-03T10:42:35.188316Z","iopub.status.idle":"2025-03-03T10:42:35.195291Z","shell.execute_reply.started":"2025-03-03T10:42:35.188286Z","shell.execute_reply":"2025-03-03T10:42:35.194169Z"}},"outputs":[],"execution_count":9},{"id":"39776c15","cell_type":"code","source":"bronx_df = time_compress(bronx_df)\nmanhattan_df = time_compress(manhattan_df)","metadata":{"papermill":{"duration":0.024935,"end_time":"2025-02-07T22:31:32.814945","exception":false,"start_time":"2025-02-07T22:31:32.790010","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.197570Z","iopub.execute_input":"2025-03-03T10:42:35.198171Z","iopub.status.idle":"2025-03-03T10:42:35.232266Z","shell.execute_reply.started":"2025-03-03T10:42:35.198140Z","shell.execute_reply":"2025-03-03T10:42:35.230926Z"}},"outputs":[],"execution_count":10},{"id":"2b95d166","cell_type":"code","source":"df_filtered = bronx_df[(bronx_df['Date / Time'].dt.hour >= 2) & (bronx_df['Date / Time'].dt.hour < 3)]\ndf_filtered","metadata":{"papermill":{"duration":0.020072,"end_time":"2025-02-07T22:31:32.842792","exception":false,"start_time":"2025-02-07T22:31:32.822720","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.233900Z","iopub.execute_input":"2025-03-03T10:42:35.234316Z","iopub.status.idle":"2025-03-03T10:42:35.259417Z","shell.execute_reply.started":"2025-03-03T10:42:35.234284Z","shell.execute_reply":"2025-03-03T10:42:35.257736Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [Date / Time, surface_air_temp, relative_humidity, avg_wind_speed, wind_direction, solar_flux]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date / Time</th>\n      <th>surface_air_temp</th>\n      <th>relative_humidity</th>\n      <th>avg_wind_speed</th>\n      <th>wind_direction</th>\n      <th>solar_flux</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"id":"a14860a6","cell_type":"code","source":"# weather_path = '/kaggle/input/ey-open-science-training-data/NY_Mesonet_Weather.xlsx'\n# def load_weather_station(xlsx_path):\n#     bronx_df = pd.read_excel(xlsx_path, sheet_name='Bronx')\n#     manhattan_df = pd.read_excel(xlsx_path, sheet_name='Manhattan')\n#     bronx_df['Date / Time'] = pd.to_datetime(bronx_df['Date / Time'])\n#     manhattan_df['Date / Time'] = pd.to_datetime(manhattan_df['Date / Time'])\n#     bronx_filtered = bronx_df[(bronx_df['Date / Time'].dt.hour >= 14) & (bronx_df['Date / Time'].dt.hour < 17)]\n#     manhattan_filtered = manhattan_df[(bronx_df['Date / Time'].dt.hour >= 14) & (manhattan_df['Date / Time'].dt.hour < 17)]\n#     bronx_df = time_compress(bronx_filtered)\n#     manhattan_df = time_compress(manhattan_filtered)\n#     # bronx_df['Date / Time'] = pd.to_datetime(bronx_df['Date / Time'])\n#     # manhattan_df['Date / Time'] = pd.to_datetime(manhattan_df['Date / Time'])\n#     # bronx_column_names = {\n#     # bronx_df.columns[1]: 'surface_air_temp',\n#     # bronx_df.columns[2]: 'relative_humidity',\n#     # bronx_df.columns[3]: 'avg_wind_speed',\n#     # bronx_df.columns[4]: 'wind_direction',\n#     # bronx_df.columns[5]: 'solar_flux'\n#     # }\n#     # manhattan_column_names = {\n#     # manhattan_df.columns[1]: 'surface_air_temp',\n#     # manhattan_df.columns[2]: 'relative_humidity',\n#     # manhattan_df.columns[3]: 'avg_wind_speed',\n#     # manhattan_df.columns[4]: 'wind_direction',\n#     # manhattan_df.columns[5]: 'solar_flux'\n#     # }\n#     # bronx_df.rename(columns=bronx_column_names, inplace=True)\n#     # manhattan_df.rename(columns=manhattan_column_names, inplace=True)\n#     bronx_df.sort_values('Date / Time', inplace=True)\n#     manhattan_df.sort_values('Date / Time', inplace=True)\n#     return bronx_df, manhattan_df\n\n# def pick_station(lat, lon):\n\n#     if 40.80 <= lat <= 40.92 and -73.93 <= lon <= -73.79:\n#         return \"Bronx\"\n#     # elif 40.70 <= lat <= 40.88 and -74.02 <= lon <= -73.91:\n#     #     return \"Manhattan\"\n#     else: \n#         return \"Manhattan\"\n\n# def match_nearest_weather(row_dt, weather_df):\n#     print()\n#     diffs = (weather_df['Date / Time'] - row_dt).abs()\n#     idx_min = diffs.idxmin()\n#     return weather_df.loc[idx_min]\n\n# def add_weather_to_train(train_df, bronx_df, manh_df):\n\n#     weather_cols = [\"Air Temp at Surface [degC]\", \"Relative Humidity [percent]\",\n#                     \"Avg Wind Speed [m/s]\", \"Wind Direction [degrees]\", \"Solar Flux [W/m^2]\"]\n#     at_surface = []\n#     rh = []\n#     wind_speed = []\n#     wind_dir = []\n#     solar_flux = []\n\n#     for _, row in train_df.iterrows():\n\n#         stn = pick_station(row['Latitude'], row['Longitude'])\n#         if stn == 'Bronx':\n#             wdf = bronx_df\n#         else:\n#             wdf = manh_df\n\n#         row_dt = pd.to_datetime(row['datetime'])\n#         match = match_nearest_weather(row_dt, wdf)\n\n#         at_surface.append(match[\"Air Temp at Surface [degC]\"])\n#         rh.append(match[\"Relative Humidity [percent]\"])\n#         wind_speed.append(match[\"Avg Wind Speed [m/s]\"])\n#         wind_dir.append(match[\"Wind Direction [degrees]\"])\n#         solar_flux.append(match[\"Solar Flux [W/m^2]\"])\n\n#     train_df[\"Weather_AirTemp\"] = at_surface\n#     train_df[\"Weather_RH\"]      = rh\n#     train_df[\"Weather_WindSpd\"] = wind_speed\n#     train_df[\"Weather_WindDir\"] = wind_dir\n#     train_df[\"Weather_Solar\"]   = solar_flux\n\n#     return train_df\n\n# weather_bronx, weather_manh = load_weather_station(weather_path)\n# train_enh_1 = add_weather_to_train(train_df, weather_bronx, weather_manh)","metadata":{"papermill":{"duration":5.102323,"end_time":"2025-02-07T22:31:37.952950","exception":false,"start_time":"2025-02-07T22:31:32.850627","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.260443Z","iopub.execute_input":"2025-03-03T10:42:35.260731Z","iopub.status.idle":"2025-03-03T10:42:35.283932Z","shell.execute_reply.started":"2025-03-03T10:42:35.260707Z","shell.execute_reply":"2025-03-03T10:42:35.282651Z"}},"outputs":[],"execution_count":12},{"id":"9b8f2f2a","cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nweather_path = '/kaggle/input/ey-open-science-training-data/NY_Mesonet_Weather.xlsx'\n\ndef load_weather_station(xlsx_path, upper, lower):\n    \"\"\"Load weather data and compress time from 2–5 PM to 3–4 PM\"\"\"\n    bronx_df = pd.read_excel(xlsx_path, sheet_name='Bronx')\n    manhattan_df = pd.read_excel(xlsx_path, sheet_name='Manhattan')\n    \n    def process_and_compress(df):\n        df['Date / Time'] = pd.to_datetime(df['Date / Time'])\n        # Filter to original window 2–5 PM (i.e. 14:00 to 17:00)\n        df['hour'] = df['Date / Time'].dt.hour\n        df = df[(df['hour'] >= 14) & (df['hour'] < 17)]\n        # Convert time to decimal hours\n        df['time_hours'] = (df['Date / Time'].dt.hour +\n                            df['Date / Time'].dt.minute/60.0 +\n                            df['Date / Time'].dt.second/3600.0)\n        # Linear compression from original [14,17) to new [15,16)\n        orig_lower, orig_upper = lower, upper\n        new_lower, new_upper = 15, 16\n        df['compressed_time'] = new_lower + (df['time_hours'] - orig_lower) * ((new_upper - new_lower) / (orig_upper - orig_lower))\n        # Replace Date / Time with normalized date plus compressed time\n        df['Date / Time'] = df['Date / Time'].dt.normalize() + pd.to_timedelta(df['compressed_time'], unit='h')\n        df.sort_values('Date / Time', inplace=True)\n        df.drop(columns=['hour', 'time_hours', 'compressed_time'], inplace=True)\n        return df\n\n    bronx_df = process_and_compress(bronx_df)\n    manhattan_df = process_and_compress(manhattan_df)\n    return bronx_df, manhattan_df\n\ndef pick_station(lat, lon):\n    if 40.80 <= lat <= 40.92 and -73.93 <= lon <= -73.79:\n        return \"Bronx\"\n    else:\n        return \"Manhattan\"\n\ndef get_closest_weather(target_dt, weather_df):\n    \"\"\"Return weather features from the row with the closest datetime\"\"\"\n    same_day = weather_df[weather_df['Date / Time'].dt.date == target_dt.date()]\n    if same_day.empty:\n        return None\n    diffs = (same_day['Date / Time'] - target_dt).abs()\n    idx_min = diffs.idxmin()\n    row = same_day.loc[idx_min]\n    return {\n        'AirTemp': row['Air Temp at Surface [degC]'],\n        'RH': row['Relative Humidity [percent]'],\n        'WindSpd': row['Avg Wind Speed [m/s]'],\n        'WindDir': row['Wind Direction [degrees]'],\n        'Solar': row['Solar Flux [W/m^2]']\n    }\n\ndef add_weather_to_train(train_df, bronx_df, manh_df):\n    \"\"\"Match each train row to the closest weather row (after compression)\"\"\"\n    bronx_dates = {d: g for d, g in bronx_df.groupby(bronx_df['Date / Time'].dt.date)}\n    manh_dates = {d: g for d, g in manh_df.groupby(manh_df['Date / Time'].dt.date)}\n    \n    weather_cols = ['Weather_AirTemp', 'Weather_RH', 'Weather_WindSpd', 'Weather_WindDir', 'Weather_Solar']\n    for col in weather_cols:\n        train_df[col] = np.nan\n    \n    train_df['datetime'] = pd.to_datetime(train_df['datetime'])\n    for idx, row in train_df.iterrows():\n        stn = pick_station(row['Latitude'], row['Longitude'])\n        target_date = row['datetime'].date()\n        weather_data = bronx_dates.get(target_date) if stn == 'Bronx' else manh_dates.get(target_date)\n        if weather_data is not None:\n            features = get_closest_weather(row['datetime'], weather_data)\n            if features is not None:\n                train_df.at[idx, 'Weather_AirTemp'] = features['AirTemp']\n                train_df.at[idx, 'Weather_RH'] = features['RH']\n                train_df.at[idx, 'Weather_WindSpd'] = features['WindSpd']\n                train_df.at[idx, 'Weather_WindDir'] = features['WindDir']\n                train_df.at[idx, 'Weather_Solar'] = features['Solar']\n    return train_df\n\n# Usage\n\n","metadata":{"papermill":{"duration":8.426314,"end_time":"2025-02-07T22:31:46.391531","exception":false,"start_time":"2025-02-07T22:31:37.965217","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.285425Z","iopub.execute_input":"2025-03-03T10:42:35.285854Z","iopub.status.idle":"2025-03-03T10:42:35.310321Z","shell.execute_reply.started":"2025-03-03T10:42:35.285811Z","shell.execute_reply":"2025-03-03T10:42:35.308905Z"}},"outputs":[],"execution_count":13},{"id":"422888a3","cell_type":"code","source":"# weather_bronx, weather_manh = load_weather_station(weather_path, 12, 17)\n# train_enh_12_17 = add_weather_to_train(train_df.copy(), weather_bronx, weather_manh)\n# train_enh_12_17.to_csv('train_enh_12_17.csv', index=False)","metadata":{"papermill":{"duration":0.028588,"end_time":"2025-02-07T22:31:46.431898","exception":false,"start_time":"2025-02-07T22:31:46.403310","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.311553Z","iopub.execute_input":"2025-03-03T10:42:35.311953Z","iopub.status.idle":"2025-03-03T10:42:35.333567Z","shell.execute_reply.started":"2025-03-03T10:42:35.311917Z","shell.execute_reply":"2025-03-03T10:42:35.332384Z"}},"outputs":[],"execution_count":14},{"id":"62e6200b-3a90-49f2-ad47-5d0be593b6b2","cell_type":"code","source":"# weather_bronx, weather_manh = load_weather_station(weather_path, 13, 17)\n# train_enh_13_17 = add_weather_to_train(train_df.copy(), weather_bronx, weather_manh)\n# train_enh_13_17.to_csv('train_enh_13_17.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.334693Z","iopub.execute_input":"2025-03-03T10:42:35.335192Z","iopub.status.idle":"2025-03-03T10:42:35.352265Z","shell.execute_reply.started":"2025-03-03T10:42:35.335083Z","shell.execute_reply":"2025-03-03T10:42:35.351115Z"}},"outputs":[],"execution_count":15},{"id":"02f6680c-11e9-4e65-b11e-15b223344778","cell_type":"code","source":"# weather_bronx, weather_manh = load_weather_station(weather_path, 14, 18)\n# train_enh_14_18 = add_weather_to_train(train_df.copy(), weather_bronx, weather_manh)\n# train_enh_14_18.to_csv('train_enh_14_18.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.353647Z","iopub.execute_input":"2025-03-03T10:42:35.354054Z","iopub.status.idle":"2025-03-03T10:42:35.378473Z","shell.execute_reply.started":"2025-03-03T10:42:35.354014Z","shell.execute_reply":"2025-03-03T10:42:35.377323Z"}},"outputs":[],"execution_count":16},{"id":"08c7b2b7-a351-4239-83dd-e5843c8b032c","cell_type":"code","source":"# weather_bronx, weather_manh = load_weather_station(weather_path, 14, 19)\n# train_enh_14_19 = add_weather_to_train(train_df.copy(), weather_bronx, weather_manh)\n# train_enh_14_19.to_csv('train_enh_14_19.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.379512Z","iopub.execute_input":"2025-03-03T10:42:35.380031Z","iopub.status.idle":"2025-03-03T10:42:35.397741Z","shell.execute_reply.started":"2025-03-03T10:42:35.379991Z","shell.execute_reply":"2025-03-03T10:42:35.396549Z"}},"outputs":[],"execution_count":17},{"id":"33d28448-21c4-4b5e-b539-336c0d899714","cell_type":"code","source":"# weather_bronx, weather_manh = load_weather_station(weather_path, 14, 20)\n# train_enh_14_20 = add_weather_to_train(train_df.copy(), weather_bronx, weather_manh)\n# train_enh_14_20.to_csv('train_enh_14_20.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.398877Z","iopub.execute_input":"2025-03-03T10:42:35.399273Z","iopub.status.idle":"2025-03-03T10:42:35.417793Z","shell.execute_reply.started":"2025-03-03T10:42:35.399236Z","shell.execute_reply":"2025-03-03T10:42:35.416519Z"}},"outputs":[],"execution_count":18},{"id":"e2d935e2-6268-49f1-9d8e-2a321e2e5dd7","cell_type":"code","source":"# weather_bronx, weather_manh = load_weather_station(weather_path, 6, 20)\n# train_enh_6_20 = add_weather_to_train(train_df.copy(), weather_bronx, weather_manh)\n# train_enh_6_20.to_csv('train_enh_6_20.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.418799Z","iopub.execute_input":"2025-03-03T10:42:35.419076Z","iopub.status.idle":"2025-03-03T10:42:35.435562Z","shell.execute_reply.started":"2025-03-03T10:42:35.419054Z","shell.execute_reply":"2025-03-03T10:42:35.434109Z"}},"outputs":[],"execution_count":19},{"id":"23247fcf-bfba-4a4c-9f7d-d2516a65658d","cell_type":"code","source":"# weather_bronx, weather_manh = load_weather_station(weather_path, 11, 20)\n# train_enh_11_20 = add_weather_to_train(train_df.copy(), weather_bronx, weather_manh)\n# train_enh_11_20.to_csv('train_enh_14_20.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.436792Z","iopub.execute_input":"2025-03-03T10:42:35.437120Z","iopub.status.idle":"2025-03-03T10:42:35.454129Z","shell.execute_reply.started":"2025-03-03T10:42:35.437094Z","shell.execute_reply":"2025-03-03T10:42:35.452749Z"}},"outputs":[],"execution_count":20},{"id":"aa8ccb6e","cell_type":"markdown","source":"# Approach_2","metadata":{"papermill":{"duration":0.011858,"end_time":"2025-02-07T22:31:46.491513","exception":false,"start_time":"2025-02-07T22:31:46.479655","status":"completed"},"tags":[]}},{"id":"12c49be6","cell_type":"code","source":"# def normalize_time_window(datetime, target_start_hour=3, target_end_hour=4):\n#     \"\"\"\n#     Normalize input datetime to a target time window\n    \n#     Args:\n#     - datetime: Input datetime\n#     - target_start_hour: Start of desired time window (default 3)\n#     - target_end_hour: End of desired time window (default 4)\n    \n#     Returns:\n#     - Normalized datetime within target window\n#     \"\"\"\n#     hour = datetime.hour\n    \n#     # If hour is already in target window, return original datetime\n#     if target_start_hour <= hour < target_end_hour:\n#         return datetime\n    \n#     # Adjust datetime to nearest target window\n#     if hour < target_start_hour:\n#         # Earlier in the day, shift to target start hour\n#         normalized_datetime = datetime.replace(hour=target_start_hour, minute=0, second=0, microsecond=0)\n#     else:\n#         # Later in the day, shift to next day's target start hour\n#         normalized_datetime = (datetime + pd.Timedelta(days=1)).replace(hour=target_start_hour, minute=0, second=0, microsecond=0)\n    \n#     return normalized_datetime\n\n# def load_weather_station(xlsx_path):\n#     bronx_df = pd.read_excel(xlsx_path, sheet_name='Bronx')\n#     manhattan_df = pd.read_excel(xlsx_path, sheet_name='Manhattan')\n    \n#     bronx_df['Date / Time'] = pd.to_datetime(bronx_df['Date / Time'])\n#     manhattan_df['Date / Time'] = pd.to_datetime(manhattan_df['Date / Time'])\n    \n#     # Add normalized time column\n#     bronx_df['Normalized Time'] = bronx_df['Date / Time'].apply(normalize_time_window)\n#     manhattan_df['Normalized Time'] = manhattan_df['Date / Time'].apply(normalize_time_window)\n    \n#     bronx_df.sort_values('Normalized Time', inplace=True)\n#     manhattan_df.sort_values('Normalized Time', inplace=True)\n    \n#     return bronx_df, manhattan_df\n\n# def pick_station(lat, lon):\n#     if 40.80 <= lat <= 40.92 and -73.93 <= lon <= -73.79:\n#         return \"Bronx\"\n#     else:\n#         return \"Manhattan\"\n\n# def match_nearest_weather(row_dt, weather_df):\n#     # Use normalized time for matching\n#     normalized_row_dt = normalize_time_window(row_dt)\n#     diffs = (weather_df['Normalized Time'] - normalized_row_dt).abs()\n#     idx_min = diffs.idxmin()\n#     return weather_df.loc[idx_min]\n\n# def add_weather_to_train(train_df, bronx_df, manh_df):\n#     weather_cols = [\n#         \"Air Temp at Surface [degC]\", \n#         \"Relative Humidity [percent]\", \n#         \"Avg Wind Speed [m/s]\", \n#         \"Wind Direction [degrees]\", \n#         \"Solar Flux [W/m^2]\"\n#     ]\n    \n#     at_surface, rh, wind_speed, wind_dir, solar_flux = [], [], [], [], []\n    \n#     for _, row in train_df.iterrows():\n#         stn = pick_station(row['Latitude'], row['Longitude'])\n#         wdf = bronx_df if stn == 'Bronx' else manh_df\n        \n#         row_dt = pd.to_datetime(row['datetime'])\n#         match = match_nearest_weather(row_dt, wdf)\n        \n#         at_surface.append(match[\"Air Temp at Surface [degC]\"])\n#         rh.append(match[\"Relative Humidity [percent]\"])\n#         wind_speed.append(match[\"Avg Wind Speed [m/s]\"])\n#         wind_dir.append(match[\"Wind Direction [degrees]\"])\n#         solar_flux.append(match[\"Solar Flux [W/m^2]\"])\n    \n#     train_df[\"Weather_AirTemp\"] = at_surface\n#     train_df[\"Weather_RH\"] = rh\n#     train_df[\"Weather_WindSpd\"] = wind_speed\n#     train_df[\"Weather_WindDir\"] = wind_dir\n#     train_df[\"Weather_Solar\"] = solar_flux\n    \n#     return train_df\n\n# # Usage remains the same\n# weather_path = '/kaggle/input/ey-open-science-training-data/NY_Mesonet_Weather.xlsx'\n# weather_bronx, weather_manh = load_weather_station(weather_path)\n# train_enh = add_weather_to_train(train_df, weather_bronx, weather_manh)","metadata":{"papermill":{"duration":0.019102,"end_time":"2025-02-07T22:31:46.522775","exception":false,"start_time":"2025-02-07T22:31:46.503673","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.455163Z","iopub.execute_input":"2025-03-03T10:42:35.455574Z","iopub.status.idle":"2025-03-03T10:42:35.473787Z","shell.execute_reply.started":"2025-03-03T10:42:35.455536Z","shell.execute_reply":"2025-03-03T10:42:35.472247Z"}},"outputs":[],"execution_count":21},{"id":"533fec32","cell_type":"code","source":"# import pandas as pd\n# import numpy as np\n\n# # Example file paths (adjust as needed)\n# weather_path = '/kaggle/input/ey-open-science-training-data/NY_Mesonet_Weather.xlsx'\n# # Suppose your training DataFrame is already loaded as train_df:\n# # train_df = pd.read_csv('your_train_file.csv')\n\n# # --- Step 1: Load and rename weather data ---\n\n# def load_weather_station(xlsx_path):\n#     # Load weather data from two sheets\n#     bronx_df = pd.read_excel(xlsx_path, sheet_name='Bronx')\n#     manhattan_df = pd.read_excel(xlsx_path, sheet_name='Manhattan')\n    \n#     # Convert the 'Date / Time' column to datetime if needed\n#     bronx_df['Date / Time'] = pd.to_datetime(bronx_df['Date / Time'])\n#     manhattan_df['Date / Time'] = pd.to_datetime(manhattan_df['Date / Time'])\n    \n#     # Rename columns using your provided dictionaries\n#     bronx_column_names = {\n#         bronx_df.columns[1]: 'surface_air_temp',\n#         bronx_df.columns[2]: 'relative_humidity',\n#         bronx_df.columns[3]: 'avg_wind_speed',\n#         bronx_df.columns[4]: 'wind_direction',\n#         bronx_df.columns[5]: 'solar_flux'\n#     }\n#     manhattan_column_names = {\n#         manhattan_df.columns[1]: 'surface_air_temp',\n#         manhattan_df.columns[2]: 'relative_humidity',\n#         manhattan_df.columns[3]: 'avg_wind_speed',\n#         manhattan_df.columns[4]: 'wind_direction',\n#         manhattan_df.columns[5]: 'solar_flux'\n#     }\n#     bronx_df.rename(columns=bronx_column_names, inplace=True)\n#     manhattan_df.rename(columns=manhattan_column_names, inplace=True)\n    \n#     # (Optional) sort by time if needed\n#     bronx_df.sort_values('Date / Time', inplace=True)\n#     manhattan_df.sort_values('Date / Time', inplace=True)\n    \n#     return bronx_df, manhattan_df\n\n# weather_bronx, weather_manh = load_weather_station(weather_path)\n\n# # --- Step 2: Define a function to pick station based on coordinates ---\n# def pick_station(lat, lon):\n#     # Simple example: if within Bronx bounds, return 'Bronx', else 'Manhattan'\n#     if 40.80 <= lat <= 40.92 and -73.93 <= lon <= -73.79:\n#         return \"Bronx\"\n#     else:\n#         return \"Manhattan\"\n\n# # --- Step 3: Impute weather features into train_df using fixed chunks ---\n# def add_weather_to_train(train_df, bronx_df, manhattan_df):\n#     # Ensure a copy and convert datetime column to datetime type, then sort\n#     train_df = train_df.copy()\n#     train_df['datetime'] = pd.to_datetime(train_df['datetime'])\n#     train_df.sort_values('datetime', inplace=True)\n    \n#     weather_features = ['surface_air_temp', 'relative_humidity', 'avg_wind_speed', 'wind_direction', 'solar_flux']\n    \n#     # Create empty columns for weather features\n#     for feat in weather_features:\n#         train_df[feat] = np.nan\n\n#     # Determine station for each training row\n#     train_df['station'] = train_df.apply(lambda row: pick_station(row['Latitude'], row['Longitude']), axis=1)\n    \n#     # Process Bronx rows: assign each chunk of train rows the corresponding weather row\n#     bronx_train = train_df[train_df['station'] == 'Bronx'].copy()\n#     bronx_train.sort_values('datetime', inplace=True)\n#     chunk_size_bronx = 31\n#     n_chunks_bronx = int(np.ceil(len(bronx_train) / chunk_size_bronx))\n#     for i in range(n_chunks_bronx):\n#         start = i * chunk_size_bronx\n#         end = min((i + 1) * chunk_size_bronx, len(bronx_train))\n#         weather_idx = i if i < len(bronx_df) else len(bronx_df) - 1\n#         weather_row = bronx_df.iloc[weather_idx]\n#         train_df.loc[bronx_train.index[start:end], weather_features] = weather_row[weather_features].values\n\n#     # Process Manhattan rows similarly\n#     manh_train = train_df[train_df['station'] == 'Manhattan'].copy()\n#     manh_train.sort_values('datetime', inplace=True)\n#     chunk_size_manh = 35\n#     n_chunks_manh = int(np.ceil(len(manh_train) / chunk_size_manh))\n#     for i in range(n_chunks_manh):\n#         start = i * chunk_size_manh\n#         end = min((i + 1) * chunk_size_manh, len(manh_train))\n#         weather_idx = i if i < len(manhattan_df) else len(manhattan_df) - 1\n#         weather_row = manhattan_df.iloc[weather_idx]\n#         train_df.loc[manh_train.index[start:end], weather_features] = weather_row[weather_features].values\n\n#     return train_df\n\n# # --- Example usage ---\n# # Suppose train_df is your training DataFrame (make sure it has columns 'datetime', 'Latitude', 'Longitude', etc.)\n# # For example, if you load it from a CSV:\n# # train_df = pd.read_csv('/kaggle/input/your_train.csv')\n\n# # Now, add the weather features to train_df\n# weather_path = '/kaggle/input/ey-open-science-training-data/NY_Mesonet_Weather.xlsx'\n# weather_bronx, weather_manh = load_weather_station(weather_path)\n# train_enh = add_weather_to_train(train_df, weather_bronx, weather_manh)\n# print(train_enh.head())\n","metadata":{"papermill":{"duration":0.019365,"end_time":"2025-02-07T22:31:46.554259","exception":false,"start_time":"2025-02-07T22:31:46.534894","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.474915Z","iopub.execute_input":"2025-03-03T10:42:35.475262Z","iopub.status.idle":"2025-03-03T10:42:35.489383Z","shell.execute_reply.started":"2025-03-03T10:42:35.475215Z","shell.execute_reply":"2025-03-03T10:42:35.487997Z"}},"outputs":[],"execution_count":22},{"id":"fb3d44fb","cell_type":"code","source":"# train_enh.nunique()","metadata":{"papermill":{"duration":0.016454,"end_time":"2025-02-07T22:31:46.582690","exception":false,"start_time":"2025-02-07T22:31:46.566236","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.490707Z","iopub.execute_input":"2025-03-03T10:42:35.491182Z","iopub.status.idle":"2025-03-03T10:42:35.510946Z","shell.execute_reply.started":"2025-03-03T10:42:35.491136Z","shell.execute_reply":"2025-03-03T10:42:35.509834Z"}},"outputs":[],"execution_count":23},{"id":"2265ab8a","cell_type":"code","source":"# for _, row in train_df.iterrows():\n#         stn = pick_station(row['Latitude'], row['Longitude'])\n#         if stn == 'Bronx':\n#             wdf = weather_bronx\n#         else:\n#             wdf = weather_manh","metadata":{"papermill":{"duration":0.016511,"end_time":"2025-02-07T22:31:46.611151","exception":false,"start_time":"2025-02-07T22:31:46.594640","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.512114Z","iopub.execute_input":"2025-03-03T10:42:35.512675Z","iopub.status.idle":"2025-03-03T10:42:35.528176Z","shell.execute_reply.started":"2025-03-03T10:42:35.512630Z","shell.execute_reply":"2025-03-03T10:42:35.526903Z"}},"outputs":[],"execution_count":24},{"id":"d91a1821","cell_type":"code","source":"# train_df.loc[train_df['borough'] == 'Bronx']['borough']","metadata":{"papermill":{"duration":0.020429,"end_time":"2025-02-07T22:31:46.644276","exception":false,"start_time":"2025-02-07T22:31:46.623847","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.529525Z","iopub.execute_input":"2025-03-03T10:42:35.529997Z","iopub.status.idle":"2025-03-03T10:42:35.546128Z","shell.execute_reply.started":"2025-03-03T10:42:35.529932Z","shell.execute_reply":"2025-03-03T10:42:35.544888Z"}},"outputs":[],"execution_count":25},{"id":"579c9d58","cell_type":"code","source":"# def merge_features(df, bronx_feats, manh_feats):\n#     \"\"\"Merge processed weather features based on location\"\"\"\n#     df['borough'] = df.apply(lambda x: pick_station(x['Latitude'], x['Longitude']), axis=1)\n    \n#     # Create borough feature matrix\n#     weather_data = pd.DataFrame({\n#         'Bronx': bronx_feats,\n#         'Manhattan': manh_feats\n#     }).T\n    \n#     return df.merge(weather_data, left_on='borough', right_index=True)\n\n# train_enh = merge_features(train_enh, bronx_features, manh_features)\n# test_enh = merge_features(test_df.copy(), bronx_features, manh_features)","metadata":{"papermill":{"duration":0.018325,"end_time":"2025-02-07T22:31:46.674844","exception":false,"start_time":"2025-02-07T22:31:46.656519","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.547238Z","iopub.execute_input":"2025-03-03T10:42:35.547625Z","iopub.status.idle":"2025-03-03T10:42:35.565907Z","shell.execute_reply.started":"2025-03-03T10:42:35.547589Z","shell.execute_reply":"2025-03-03T10:42:35.564635Z"}},"outputs":[],"execution_count":26},{"id":"916e29b8","cell_type":"code","source":"# from sklearn.neighbors import NearestNeighbors\n\n# def enhanced_spatial_impute(train_df, test_df, feature_cols):\n#     \"\"\"Weighted spatial imputation using Haversine distance\"\"\"\n#     # Convert to radians for haversine metric\n#     train_rad = np.deg2rad(train_df[['Latitude', 'Longitude']])\n#     test_rad = np.deg2rad(test_df[['Latitude', 'Longitude']])\n    \n#     # Find 10 nearest neighbors\n#     nn = NearestNeighbors(n_neighbors=10, metric='haversine')\n#     nn.fit(train_rad)\n#     distances, indices = nn.kneighbors(test_rad)\n    \n#     # Inverse distance weighting\n#     weights = 1 / (distances + 1e-6)\n#     weights /= weights.sum(axis=1)[:, None]\n    \n#     # Impute features\n#     for col in feature_cols:\n#         test_df[col] = (train_df.iloc[indices.flatten()][col].values.reshape(indices.shape) * weights).sum(axis=1)\n    \n#     return test_df\n\n# # Impute weather features\n# weather_features = ['diurnal_temp_range', 'morning_warming_rate', 'thermal_inertia']\n# test_enh = enhanced_spatial_impute(train_enh, test_enh, weather_features)\n","metadata":{"papermill":{"duration":0.016749,"end_time":"2025-02-07T22:31:46.704543","exception":false,"start_time":"2025-02-07T22:31:46.687794","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.571645Z","iopub.execute_input":"2025-03-03T10:42:35.572225Z","iopub.status.idle":"2025-03-03T10:42:35.585907Z","shell.execute_reply.started":"2025-03-03T10:42:35.572182Z","shell.execute_reply":"2025-03-03T10:42:35.584685Z"}},"outputs":[],"execution_count":27},{"id":"0325766f","cell_type":"code","source":"# import pandas as pd\n# import numpy as np\n# from datetime import datetime\n# import math\n\n# # -----------------------------\n# # 1. Load Weather Data from XLSX\n# # -----------------------------\n# def load_weather_stations(xlsx_path):\n#     \"\"\"\n#     Loads the weather data from two sheets (Bronx and Manhattan) from an XLSX file.\n#     Returns two DataFrames.\n#     \"\"\"\n#     bronx_df = pd.read_excel(xlsx_path, sheet_name=\"Bronx\")\n#     manh_df   = pd.read_excel(xlsx_path, sheet_name=\"Manhattan\")\n    \n#     # Convert 'Date / Time' to datetime objects\n#     bronx_df[\"Date / Time\"] = pd.to_datetime(bronx_df[\"Date / Time\"])\n#     manh_df[\"Date / Time\"]   = pd.to_datetime(manh_df[\"Date / Time\"])\n    \n#     return bronx_df, manh_df\n\n# # -----------------------------\n# # 2. Aggregate Weather with Time Weighting\n# # -----------------------------\n# def weighted_weather_aggregate(weather_df, target_time_str=\"15:30:00\", bandwidth=30):\n#     \"\"\"\n#     Given a weather DataFrame (with 'Date / Time'), compute a weighted average\n#     for each weather variable using a Gaussian weight on the minutes difference\n#     from target_time (default 15:30).\n    \n#     bandwidth is in minutes.\n#     Returns a dictionary of aggregated weather values.\n#     \"\"\"\n#     # Convert target_time_str to a datetime.time object\n#     target_time = datetime.strptime(target_time_str, \"%H:%M:%S\").time()\n    \n#     # For each row, compute time difference (in minutes) from target_time\n#     def time_diff_minutes(dt):\n#         # dt is a Timestamp; extract time and compute difference in minutes from target_time.\n#         t = dt.time()\n#         # Convert times to minutes from midnight:\n#         minutes = t.hour * 60 + t.minute\n#         target_minutes = target_time.hour * 60 + target_time.minute\n#         return abs(minutes - target_minutes)\n    \n#     weather_df[\"time_diff\"] = weather_df[\"Date / Time\"].apply(time_diff_minutes)\n#     # Compute Gaussian weights: weight = exp( - (diff/bandwidth)^2 )\n#     weather_df[\"weight\"] = np.exp(-(weather_df[\"time_diff\"] / bandwidth) ** 2)\n    \n#     # List of weather variables to aggregate (adjust column names as needed)\n#     vars_to_agg = [\"Air Temp at Surface [degC]\", \"Relative Humidity [percent]\",\n#                      \"Avg Wind Speed [m/s]\", \"Wind Direction [degrees]\", \"Solar Flux [W/m^2]\"]\n    \n#     agg_dict = {}\n#     for var in vars_to_agg:\n#         # Weighted average: sum(var*weight) / sum(weight)\n#         weighted_avg = (weather_df[var] * weather_df[\"weight\"]).sum() / weather_df[\"weight\"].sum()\n#         agg_dict[var] = weighted_avg\n        \n#         # Also add standard deviation weighted (optional)\n#         # weighted_std = np.sqrt(((weather_df[var] - weighted_avg)**2 * weather_df[\"weight\"]).sum() / weather_df[\"weight\"].sum())\n#         # agg_dict[var + \" (std)\"] = weighted_std\n\n#     return agg_dict\n\n# # -----------------------------\n# # 3. Robust Station Assignment Using Coordinates\n# # -----------------------------\n# def assign_station(lat, lon, station_centroids):\n#     \"\"\"\n#     Given a latitude and longitude, assign the station based on nearest centroid.\n#     station_centroids is a dict, e.g., {\"Bronx\": (lat1, lon1), \"Manhattan\": (lat2, lon2)}.\n#     Returns the station name.\n#     \"\"\"\n#     def haversine(lat1, lon1, lat2, lon2):\n#         # Calculate the great circle distance between two points on Earth (in km)\n#         R = 6371  # km\n#         dlat = math.radians(lat2 - lat1)\n#         dlon = math.radians(lon2 - lon1)\n#         a = math.sin(dlat/2)**2 + math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(dlon/2)**2\n#         c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n#         return R * c\n\n#     best_station = None\n#     best_dist = float(\"inf\")\n#     for stn, (stn_lat, stn_lon) in station_centroids.items():\n#         d = haversine(lat, lon, stn_lat, stn_lon)\n#         if d < best_dist:\n#             best_dist = d\n#             best_station = stn\n#     return best_station\n\n# # -----------------------------\n# # 4. Merge Weather Features into Train and Test\n# # -----------------------------\n# def merge_weather_features(train_df, test_df, weather_xlsx_path):\n#     \"\"\"\n#     - Loads weather data from the XLSX file (two sheets: Bronx and Manhattan).\n#     - Aggregates weather using a Gaussian weight centered at 15:30.\n#     - Uses robust station assignment (via nearest station centroid) to assign weather features.\n#     - For train, use the actual datetime to get the weighted aggregate; for test, use nearest spatial assignment.\n    \n#     Returns updated train_df and test_df with new weather columns.\n#     \"\"\"\n#     # Load weather data\n#     bronx_df, manh_df = load_weather_stations(weather_xlsx_path)\n#     # Aggregate weather for each station using the entire day but weighted around 15:30\n#     bronx_agg = weighted_weather_aggregate(bronx_df, target_time_str=\"15:30:00\", bandwidth=30)\n#     manh_agg  = weighted_weather_aggregate(manh_df, target_time_str=\"15:30:00\", bandwidth=30)\n    \n#     # Define station centroids for robust assignment (example coordinates; adjust as needed)\n#     station_centroids = {\n#         \"Bronx\": (40.84, -73.87),\n#         \"Manhattan\": (40.75, -73.98)\n#     }\n    \n#     # For train data: we have datetime, so we can average over the minute differences if desired.\n#     # Here, we'll simply assign the station based on coordinates.\n#     def assign_and_get_weather(row):\n#         stn = assign_station(row[\"Latitude\"], row[\"Longitude\"], station_centroids)\n#         row[\"station\"] = stn\n#         if stn == \"Bronx\":\n#             return pd.Series(bronx_agg)\n#         else:\n#             return pd.Series(manh_agg)\n    \n#     # For train, apply for each row.\n#     train_weather = train_df.apply(assign_and_get_weather, axis=1)\n#     train_df = pd.concat([train_df, train_weather], axis=1)\n    \n#     # For test, if no datetime is provided, do the same based on coordinates.\n#     test_weather = test_df.apply(assign_and_get_weather, axis=1)\n#     test_df = pd.concat([test_df, test_weather], axis=1)\n    \n#     # Remove temporary station column if desired.\n#     # train_df.drop(columns=\"station\", inplace=True)\n#     # test_df.drop(columns=\"station\", inplace=True)\n    \n#     return train_df, test_df\n\n\n# # Merge weather features using the full weather dataset\n# train_df, test_df = merge_weather_features(train_df, test_df, weather_path)\n\n# # Save the new CSV files\n# train_df.to_csv(\"train_with_weather.csv\", index=False)\n# test_df.to_csv(\"test_with_weather.csv\", index=False)\n\n# print(\"Weather features merged successfully.\")\n","metadata":{"papermill":{"duration":0.019333,"end_time":"2025-02-07T22:31:46.735744","exception":false,"start_time":"2025-02-07T22:31:46.716411","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.588417Z","iopub.execute_input":"2025-03-03T10:42:35.589021Z","iopub.status.idle":"2025-03-03T10:42:35.609886Z","shell.execute_reply.started":"2025-03-03T10:42:35.588984Z","shell.execute_reply":"2025-03-03T10:42:35.608893Z"}},"outputs":[],"execution_count":28},{"id":"9d4890cf","cell_type":"markdown","source":"# Approach_3","metadata":{"papermill":{"duration":0.013943,"end_time":"2025-02-07T22:31:46.764621","exception":false,"start_time":"2025-02-07T22:31:46.750678","status":"completed"},"tags":[]}},{"id":"592c5237","cell_type":"code","source":"# import pandas as pd\n# import numpy as np\n# from sklearn.decomposition import PCA\n\n# def create_station_pca_features(weather_df, n_components=3):\n#     \"\"\"\n#     1) For each row in weather_df (times from 6:00–20:00), we have columns:\n#        'Date / Time', AirTemp, RH, WindSpd, etc.\n#     2) Extract the time-series as a matrix, e.g. shape=(num_timesteps, num_vars).\n#     3) Perform PCA, keep n_components. \n#     4) Return the PCA scores as a single feature vector for that station.\n#     \"\"\"\n#     # Sort by time\n#     weather_df = weather_df.sort_values(\"Date / Time\").reset_index(drop=True)\n#     # Remove the datetime col for PCA\n#     numeric_cols = [\"Air Temp at Surface [degC]\", \"Relative Humidity [percent]\",\n#                     \"Avg Wind Speed [m/s]\", \"Wind Direction [degrees]\", \"Solar Flux [W/m^2]\"]\n#     # shape => (num_timesteps, num_vars)\n#     X = weather_df[numeric_cols].values\n#     # If missing data, fill with mean or zero\n#     X = np.nan_to_num(X, nan=np.nanmean(X, axis=0))\n    \n#     pca = PCA(n_components=n_components)\n#     scores = pca.fit_transform(X.T)  # or X, depending on dimension you want\n#     # shape => (num_vars, n_components) if we do X.T \n#     # or (num_timesteps, n_components) if we do X\n\n#     # We'll flatten or pick the first principal components in a consistent shape\n#     # E.g. flatten scores:\n#     feature_vec = scores.flatten()\n#     return feature_vec, pca.explained_variance_ratio_\n\n# def approach_1_station_features(bronx_df, manh_df):\n#     \"\"\"\n#     Returns a dict with station: feature_vector from PCA across the entire day.\n#     \"\"\"\n#     brx_vec, brx_var = create_station_pca_features(bronx_df, n_components=3)\n#     mnh_vec, mnh_var = create_station_pca_features(manh_df, n_components=3)\n#     station_features = {\n#         \"Bronx\": brx_vec,\n#         \"Manhattan\": mnh_vec\n#     }\n#     return station_features\n\n# def assign_station(lat, lon):\n#     \"\"\"\n#     Minimal bounding or logic to pick 'Bronx' vs. 'Manhattan'.\n#     Replace with your actual approach.\n#     \"\"\"\n#     return \"Bronx\" if lat>40.82 else \"Manhattan\"\n\n# def apply_approach_1(train_df, test_df, bronx_df, manh_df):\n#     \"\"\"\n#     - Creates PCA-based feature vectors for each station from the entire day.\n#     - Merges them into train/test by station assignment.\n#     \"\"\"\n#     station_feats = approach_1_station_features(bronx_df, manh_df)\n#     n_pca = len(station_feats[\"Bronx\"])  # e.g. 15 if we did n_components=3 over 5 vars, depends on shape\n\n#     # Add columns\n#     col_names = [f\"WeatherPCA_{i}\" for i in range(n_pca)]\n\n#     def get_features_for_station(row):\n#         stn = assign_station(row[\"Latitude\"], row[\"Longitude\"])\n#         vec = station_feats[stn]\n#         return pd.Series(vec)\n\n#     train_df[col_names] = train_df.apply(get_features_for_station, axis=1)\n#     test_df[col_names]  = test_df.apply(get_features_for_station, axis=1)\n#     return train_df, test_df\n\n# train_enh, test_enh = apply_approach_1(train_df, test_df, bronx_df, manhattan_df)","metadata":{"papermill":{"duration":0.022677,"end_time":"2025-02-07T22:31:46.805895","exception":false,"start_time":"2025-02-07T22:31:46.783218","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.611041Z","iopub.execute_input":"2025-03-03T10:42:35.611440Z","iopub.status.idle":"2025-03-03T10:42:35.634268Z","shell.execute_reply.started":"2025-03-03T10:42:35.611399Z","shell.execute_reply":"2025-03-03T10:42:35.633011Z"}},"outputs":[],"execution_count":29},{"id":"4c9c0c0c","cell_type":"markdown","source":"# Approach_4","metadata":{"papermill":{"duration":0.011912,"end_time":"2025-02-07T22:31:46.830839","exception":false,"start_time":"2025-02-07T22:31:46.818927","status":"completed"},"tags":[]}},{"id":"8783cfab","cell_type":"code","source":"# import pandas as pd\n# import numpy as np\n# from scipy.interpolate import interp1d\n\n# # Simplified coordinate ranges for Bronx and Manhattan\n# BRONX_BOUNDS = {'lat_min': 40.7855, 'lat_max': 40.9155, 'lon_min': -73.9332, 'lon_max': -73.7654}\n# MANHATTAN_BOUNDS = {'lat_min': 40.6990, 'lat_max': 40.8821, 'lon_min': -74.0256, 'lon_max': -73.9070}\n\n# def assign_borough(lat, lon):\n#     if (BRONX_BOUNDS['lat_min'] <= lat <= BRONX_BOUNDS['lat_max']) and \\\n#        (BRONX_BOUNDS['lon_min'] <= lon <= BRONX_BOUNDS['lon_max']):\n#         return 'Bronx'\n#     elif (MANHATTAN_BOUNDS['lat_min'] <= lat <= MANHATTAN_BOUNDS['lat_max']) and \\\n#          (MANHATTAN_BOUNDS['lon_min'] <= lon <= MANHATTAN_BOUNDS['lon_max']):\n#         return 'Manhattan'\n#     return 'Unknown'\n\n# def preprocess_weather(weather_df):\n#     weather_df['Date / Time'] = pd.to_datetime(weather_df['Date / Time']).dt.tz_localize(None)\n#     return weather_df.set_index('Date / Time')\n\n# def impute_weather_data(train_df, test_df, bronx_weather, manhattan_weather):\n#     train_df['borough'] = train_df.apply(lambda x: assign_borough(x['Latitude'], x['Longitude']), axis=1)\n#     test_df['borough'] = test_df.apply(lambda x: assign_borough(x['Latitude'], x['Longitude']), axis=1)\n\n#     # Preprocess weather data\n#     bronx_weather = preprocess_weather(bronx_weather)\n#     manhattan_weather = preprocess_weather(manhattan_weather)\n#     weather_dfs = {'Bronx': bronx_weather, 'Manhattan': manhattan_weather}\n\n#     # Interpolation for train data\n#     train_weather = []\n#     for borough in ['Bronx', 'Manhattan']:\n#         borough_train = train_df[train_df['borough'] == borough].copy()\n#         weather = weather_dfs[borough]\n\n#         time_numeric = weather.index.astype(np.int64) // 10**9\n#         borough_times = pd.to_datetime(borough_train['datetime']).astype(np.int64) // 10**9\n\n#         interpolators = {\n#             col: interp1d(time_numeric, weather[col], bounds_error=False, fill_value='extrapolate')\n#             for col in weather.columns\n#         }\n\n#         for col, interp_func in interpolators.items():\n#             borough_train[f'weather_{col}'] = interp_func(borough_times)\n\n#         train_weather.append(borough_train)\n\n#     train_imputed = pd.concat(train_weather)\n\n#     # Proximity-based interpolation for test data\n#     test_weather = []\n#     for borough in ['Bronx', 'Manhattan']:\n#         borough_test = test_df[test_df['borough'] == borough].copy()\n#         borough_train = train_imputed[train_imputed['borough'] == borough]\n\n#         # Skip if borough_train is empty\n#         if borough_train.empty:\n#             continue\n\n#         for col in [c for c in train_imputed.columns if c.startswith('weather_')]:\n#             def find_nearest_weather(row):\n#                 distances = ((borough_train['Latitude'] - row['Latitude'])**2 +\n#                              (borough_train['Longitude'] - row['Longitude'])**2)\n#                 if distances.isnull().all():\n#                     return np.nan  # Handle case where all distances are NaN\n#                 nearest_idx = distances.idxmin()\n#                 return borough_train.loc[nearest_idx, col] if nearest_idx in borough_train.index else np.nan\n\n#             borough_test[f'{col}_imputed'] = borough_test.apply(find_nearest_weather, axis=1)\n\n#         test_weather.append(borough_test)\n\n#     test_imputed = pd.concat(test_weather)\n\n#     return train_imputed, test_imputed\n\n# # Example usage\n# train_processed, test_processed = impute_weather_data(\n#     train_df=train_df,\n#     test_df=test_df,\n#     bronx_weather=bronx_df,\n#     manhattan_weather=manhattan_df\n# )\n\n# # Verify results\n# print(\"Train weather columns:\", [c for c in train_processed if c.startswith('weather_')])\n# print(\"Test weather values sample:\\n\", test_processed[['borough', 'weather_Air Temp at Surface [degC]_imputed']].head())\n# train_processed.head(3)","metadata":{"papermill":{"duration":0.020218,"end_time":"2025-02-07T22:31:46.863244","exception":false,"start_time":"2025-02-07T22:31:46.843026","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.635466Z","iopub.execute_input":"2025-03-03T10:42:35.635960Z","iopub.status.idle":"2025-03-03T10:42:35.657709Z","shell.execute_reply.started":"2025-03-03T10:42:35.635918Z","shell.execute_reply":"2025-03-03T10:42:35.656551Z"}},"outputs":[],"execution_count":30},{"id":"781e824f","cell_type":"code","source":"# new_column_names = {\n#     train_processed.columns[5]: 'surface_air_temp',\n#     train_processed.columns[6]: 'relative_humidity',\n#     train_processed.columns[7]: 'avg_wind_speed',\n#     train_processed.columns[8]: 'wind_direction',\n#     train_processed.columns[9]: 'solar_flux'\n# }\n# test_column_names = {\n#     test_processed.columns[4]: 'surface_air_temp',\n#     test_processed.columns[5]: 'relative_humidity',\n#     test_processed.columns[6]: 'avg_wind_speed',\n#     test_processed.columns[7]: 'wind_direction',\n#     test_processed.columns[8]: 'solar_flux'\n# }\n# train_processed.rename(columns=new_column_names, inplace=True)\n# test_processed.rename(columns=test_column_names, inplace=True)","metadata":{"papermill":{"duration":0.017789,"end_time":"2025-02-07T22:31:46.893395","exception":false,"start_time":"2025-02-07T22:31:46.875606","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.658911Z","iopub.execute_input":"2025-03-03T10:42:35.659278Z","iopub.status.idle":"2025-03-03T10:42:35.680645Z","shell.execute_reply.started":"2025-03-03T10:42:35.659232Z","shell.execute_reply":"2025-03-03T10:42:35.679261Z"}},"outputs":[],"execution_count":31},{"id":"72f8517e","cell_type":"markdown","source":"# Approach_5","metadata":{"papermill":{"duration":0.011391,"end_time":"2025-02-07T22:31:46.916889","exception":false,"start_time":"2025-02-07T22:31:46.905498","status":"completed"},"tags":[]}},{"id":"9d882411","cell_type":"code","source":"# import pandas as pd\n# import numpy as np\n# import geopandas as gpd\n# from shapely.geometry import Point\n\n# # ======================================================================\n# # 1. Borough Assignment with Proper Column Names\n# # ======================================================================\n\n# def assign_borough(lat, lon):\n#     \"\"\"Improved borough assignment using actual coordinate columns\"\"\"\n#     # Simplified threshold - adjust based on your coordinate analysis\n#     BRONX_NORTHERN_BOUNDARY = 40.87\n#     return \"Bronx\" if lat > BRONX_NORTHERN_BOUNDARY else \"Manhattan\"\n\n# # Apply to datasets with correct Latitude/Longitude columns\n# train_df['borough'] = train_df.apply(\n#     lambda x: assign_borough(x['Latitude'], x['Longitude']), axis=1\n# )\n# test_df['borough'] = test_df.apply(\n#     lambda x: assign_borough(x['Latitude'], x['Longitude']), axis=1\n# )\n\n# # ======================================================================\n# # 2. Weather Feature Engineering with Correct Column Names\n# # ======================================================================\n\n# def process_weather(weather_df):\n#     \"\"\"Enhanced temporal feature extraction with proper column references\"\"\"\n#     # Ensure the index is a DatetimeIndex\n#     weather_df.index = pd.to_datetime(weather_df.index, errors='coerce')\n    \n#     # Filter data between 3 PM and 4 PM\n#     weather_3pm = weather_df.between_time('15:00', '16:00').copy()\n    \n#     return pd.Series({\n#         'temp_slope': np.polyfit(\n#             np.arange(len(weather_3pm)), \n#             weather_3pm['surface_air_temp'], \n#             1\n#         )[0] if len(weather_3pm) > 1 else 0,\n#         'humidity_var': weather_3pm['relative_humidity'].var() if not weather_3pm['relative_humidity'].isna().all() else 0,\n#         'wind_dir_mode': weather_3pm['wind_direction'].mode()[0] if not weather_3pm['wind_direction'].isna().all() else 0,\n#         'solar_cumulative': weather_3pm['solar_flux'].sum(),\n#         'wind_speed_max': weather_3pm['avg_wind_speed'].max() if not weather_3pm['avg_wind_speed'].isna().all() else 0\n#     })\n\n# # Process both boroughs\n# bronx_features = process_weather(\n#     bronx_df.rename(columns={'Date / Time': 'Date/Time'}).set_index('Date/Time')\n# )\n# manhattan_features = process_weather(\n#     manhattan_df.rename(columns={'Date / Time': 'Date/Time'}).set_index('Date/Time')\n# )\n\n# # ======================================================================\n# # 3. Spatial Feature Integration\n# # ======================================================================\n\n# # Create geometries first\n# train_df['geometry'] = train_df.apply(\n#     lambda x: Point(x['Longitude'], x['Latitude']), \n#     axis=1\n# )\n# test_df['geometry'] = test_df.apply(\n#     lambda x: Point(x['Longitude'], x['Latitude']), \n#     axis=1\n# )\n\n# def calculate_density(row):\n#     \"\"\"Building density with 100m buffer\"\"\"\n#     buffer = row['geometry'].buffer(0.0009)  # ~100m at NYC latitude\n#     return len(building_density[building_density.intersects(buffer)])\n\n# # Apply density calculation\n# # train_df['building_density'] = train_df.apply(calculate_density, axis=1)\n# # test_df['building_density'] = test_df.apply(calculate_density, axis=1)\n\n# # # ======================================================================\n# # # 4. Final Feature Merging\n# # # ======================================================================\n\n# # Create feature matrix\n# weather_features = pd.DataFrame({\n#     'Bronx': bronx_features,\n#     'Manhattan': manhattan_features\n# }).T.add_prefix('weather_')\n\n# # Merge with main data\n# train_df = train_df.merge(\n#     weather_features,\n#     left_on='borough', \n#     right_index=True\n# )\n# test_df = test_df.merge(\n#     weather_features,\n#     left_on='borough', \n#     right_index=True\n# )\n\n# # ======================================================================\n# # 5. Critical Enhancements for Model Performance\n# # ======================================================================\n\n# # Add interaction features\n# train_df['temp_wind_interaction'] = (\n#     train_df['weather_temp_slope'] * \n#     train_df['weather_wind_speed_max']\n# )\n# test_df['temp_wind_interaction'] = (\n#     test_df['weather_temp_slope'] * \n#     test_df['weather_wind_speed_max']\n# )\n\n# # # Temporal alignment feature\n# # train_df['minute_offset'] = (\n# #     train_df['datetime'].dt.minute - 180\n# # )  # Minutes since 3:00 PM","metadata":{"papermill":{"duration":0.01787,"end_time":"2025-02-07T22:31:46.946301","exception":false,"start_time":"2025-02-07T22:31:46.928431","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.681894Z","iopub.execute_input":"2025-03-03T10:42:35.682282Z","iopub.status.idle":"2025-03-03T10:42:35.705389Z","shell.execute_reply.started":"2025-03-03T10:42:35.682252Z","shell.execute_reply":"2025-03-03T10:42:35.704189Z"}},"outputs":[],"execution_count":32},{"id":"d63a9910","cell_type":"code","source":"weather_cols = ['Weather_AirTemp',\n       'Weather_RH', 'Weather_WindSpd', 'Weather_WindDir', 'Weather_Solar']","metadata":{"papermill":{"duration":0.018102,"end_time":"2025-02-07T22:31:46.977270","exception":false,"start_time":"2025-02-07T22:31:46.959168","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.706436Z","iopub.execute_input":"2025-03-03T10:42:35.706814Z","iopub.status.idle":"2025-03-03T10:42:35.732052Z","shell.execute_reply.started":"2025-03-03T10:42:35.706777Z","shell.execute_reply":"2025-03-03T10:42:35.730806Z"}},"outputs":[],"execution_count":33},{"id":"d173e194-ebbe-43d7-9093-07a3326ee476","cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport geopandas as gpd\nfrom shapely.geometry import Point\nfrom sklearn.neighbors import NearestNeighbors\n\n# ------------------------------\n# Weather Processing Functions\n# ------------------------------\n\ndef load_weather_station(xlsx_path, target_lower, target_upper):\n    \"\"\"\n    Load weather data from an Excel file and compress its time information to a target time window.\n    \n    Parameters:\n      - xlsx_path: Path to the weather Excel file.\n      - target_lower: The lower bound of the target time window (e.g., 10 for 10:00).\n      - target_upper: The upper bound of the target time window (e.g., 18 for 18:00).\n    \n    The function:\n      1. Loads the Bronx and Manhattan sheets.\n      2. Processes each DataFrame:\n         - Converts 'Date / Time' to datetime.\n         - Filters rows to only those within the target window (e.g., 10:00 to 18:00).\n         - Converts the time to decimal hours.\n         - Computes the observed minimum and maximum time (orig_lower, orig_upper) in the filtered data.\n         - Linearly maps (compresses) the observed time range to exactly [target_lower, target_upper].\n         - Replaces 'Date / Time' with the normalized date plus the compressed time.\n    \n    Returns:\n      A tuple (bronx_df, manhattan_df) of the processed DataFrames.\n    \"\"\"\n    # Load sheets\n    bronx_df = pd.read_excel(xlsx_path, sheet_name='Bronx')\n    manhattan_df = pd.read_excel(xlsx_path, sheet_name='Manhattan')\n    \n    def process_and_compress(df):\n        # Convert 'Date / Time' to datetime\n        df['Date / Time'] = pd.to_datetime(df['Date / Time'])\n        \n        # Filter rows to only include records in the target window (e.g., between target_lower and target_upper)\n        df['hour'] = df['Date / Time'].dt.hour\n        df = df[(df['hour'] >= target_lower) & (df['hour'] < target_upper)]\n        \n        # Convert the time portion to decimal hours\n        df['time_hours'] = (df['Date / Time'].dt.hour +\n                            df['Date / Time'].dt.minute / 60.0 +\n                            df['Date / Time'].dt.second / 3600.0)\n        \n        # Determine the observed min and max in the filtered data\n        orig_lower, orig_upper = df['time_hours'].min(), df['time_hours'].max()\n        # Set the target window as provided\n        new_lower, new_upper = target_lower, target_upper\n        \n        # Compress (scale) the observed time range to the target window.\n        # If orig_lower == new_lower and orig_upper == new_upper, this will be an identity mapping.\n        df['compressed_time'] = new_lower + (df['time_hours'] - orig_lower) * ((new_upper - new_lower) / (orig_upper - orig_lower))\n        \n        # Replace 'Date / Time' with the normalized date plus the compressed time\n        df['Date / Time'] = df['Date / Time'].dt.normalize() + pd.to_timedelta(df['compressed_time'], unit='h')\n        \n        # Sort and clean up intermediate columns\n        df.sort_values('Date / Time', inplace=True)\n        df.drop(columns=['hour', 'time_hours', 'compressed_time'], inplace=True)\n        return df\n\n    # Process both sheets\n    bronx_df = process_and_compress(bronx_df)\n    manhattan_df = process_and_compress(manhattan_df)\n    return bronx_df, manhattan_df\n\ndef pick_station(lat, lon):\n    \"\"\"Select the weather station based on latitude and longitude.\"\"\"\n    if 40.80 <= lat <= 40.92 and -73.93 <= lon <= -73.79:\n        return \"Bronx\"\n    else:\n        return \"Manhattan\"\n\ndef get_closest_weather(target_dt, weather_df):\n    \"\"\"\n    Return weather features from the row with the closest datetime.\n    The output dictionary prefixes keys with 'Weather_'.\n    \"\"\"\n    same_day = weather_df[weather_df['Date / Time'].dt.date == target_dt.date()]\n    if same_day.empty:\n        return None\n    diffs = (same_day['Date / Time'] - target_dt).abs()\n    idx_min = diffs.idxmin()\n    row = same_day.loc[idx_min]\n    return {\n        'Weather_AirTemp': row['Air Temp at Surface [degC]'],\n        'Weather_RH': row['Relative Humidity [percent]'],\n        'Weather_WindSpd': row['Avg Wind Speed [m/s]'],\n        'Weather_WindDir': row['Wind Direction [degrees]'],\n        'Weather_Solar': row['Solar Flux [W/m^2]']\n    }\n\ndef add_weather_to_train(train_df, bronx_df, manh_df):\n    \"\"\"\n    Match each training row to the closest weather row (by datetime) and attach weather features.\n    \"\"\"\n    # Group weather data by date for quicker lookup\n    bronx_dates = {d: g for d, g in bronx_df.groupby(bronx_df['Date / Time'].dt.date)}\n    manh_dates = {d: g for d, g in manh_df.groupby(manh_df['Date / Time'].dt.date)}\n    \n    weather_cols = ['Weather_AirTemp', 'Weather_RH', 'Weather_WindSpd', 'Weather_WindDir', 'Weather_Solar']\n    for col in weather_cols:\n        train_df[col] = np.nan\n    \n    train_df['datetime'] = pd.to_datetime(train_df['datetime'])\n    for idx, row in train_df.iterrows():\n        stn = pick_station(row['Latitude'], row['Longitude'])\n        target_date = row['datetime'].date()\n        weather_data = bronx_dates.get(target_date) if stn == 'Bronx' else manh_dates.get(target_date)\n        if weather_data is not None:\n            features = get_closest_weather(row['datetime'], weather_data)\n            if features is not None:\n                for col in weather_cols:\n                    train_df.at[idx, col] = features[col]\n    return train_df\n\n# ------------------------------\n# Spatial Imputation Functions\n# ------------------------------\n\ndef df_to_gdf(df, lon_col='Longitude', lat_col='Latitude', crs='EPSG:4326'):\n    \"\"\"\n    Convert a DataFrame to a GeoDataFrame with Point geometry.\n    \"\"\"\n    geometry = [Point(xy) for xy in zip(df[lon_col], df[lat_col])]\n    return gpd.GeoDataFrame(df, geometry=geometry, crs=crs)\n\ndef impute_weather_from_train(train_gdf, test_gdf, weather_cols):\n    \"\"\"\n    Impute weather features for the test set using geopandas' sjoin_nearest.\n    Assumes train_gdf contains weather_cols and geometry.\n    \"\"\"\n    train_subset = train_gdf[weather_cols + ['geometry']]\n    joined = gpd.sjoin_nearest(test_gdf, train_subset, how=\"left\", distance_col=\"distance\")\n    joined = joined.drop(columns=['index_right', 'distance'])\n    return joined\n\n# ------------------------------\n# Integrated Processing Function\n# ------------------------------\n\ndef process_time_variants_and_impute_test(train_df, test_df, weather_path, time_variants, weather_cols):\n    \"\"\"\n    For each time variant (a tuple of (target_lower, target_upper)):\n      1. Process the weather data from the Excel file and enhance training data by matching weather features.\n      2. Convert train and test DataFrames to GeoDataFrames and reproject them.\n      3. Impute weather features for the test set using spatial nearest neighbor matching.\n      4. Save the enhanced training and imputed test sets to CSV.\n    \n    Parameters:\n      - train_df: Training DataFrame (must contain 'datetime', 'Latitude', 'Longitude').\n      - test_df: Test DataFrame (must contain 'Latitude', 'Longitude').\n      - weather_path: Path to the weather Excel file.\n      - time_variants: List of tuples, each (target_lower, target_upper). For example, [(10,18), (11,17)].\n      - weather_cols: List of weather feature column names.\n    \"\"\"\n    for target_lower, target_upper in time_variants:\n        print(f\"\\nProcessing time variant with target window [{target_lower}, {target_upper})...\")\n        \n        # Process weather data and enhance training data using the dynamic target window.\n        weather_bronx, weather_manh = load_weather_station(weather_path, target_lower, target_upper)\n        train_enh = add_weather_to_train(train_df.copy(), weather_bronx, weather_manh)\n        train_csv = f\"train_enh_{target_lower}_{target_upper}.csv\"\n        train_enh.to_csv(train_csv, index=False)\n        print(f\"Saved enhanced training data: {train_csv}\")\n        \n        # Convert DataFrames to GeoDataFrames\n        train_gdf = df_to_gdf(train_enh, lon_col='Longitude', lat_col='Latitude')\n        test_gdf = df_to_gdf(test_df.copy(), lon_col='Longitude', lat_col='Latitude')\n        \n        # Reproject to a common CRS (e.g., EPSG:2263) for accurate spatial operations\n        train_gdf = train_gdf.to_crs('EPSG:2263')\n        test_gdf = test_gdf.to_crs('EPSG:2263')\n        \n        # Impute weather features for the test set via nearest spatial neighbor matching\n        test_gdf = impute_weather_from_train(train_gdf, test_gdf, weather_cols)\n        \n        # Reproject test set back to the original CRS (EPSG:4326)\n        test_gdf = test_gdf.to_crs('EPSG:4326')\n        test_csv = f\"test_imputed_{target_lower}_{target_upper}.csv\"\n        test_gdf.to_csv(test_csv, index=False)\n        print(f\"Saved imputed test data: {test_csv}\")\n\n# ------------------------------\n# Example usage:\n# ------------------------------\n\n# Load your train and test DataFrames as needed:\n# train_df = pd.read_csv('path_to_train.csv')\n# test_df = pd.read_csv('path_to_test.csv')\n\n# Define the time variants you want to test (adjust the values as necessary)\ntime_variants_1 = [\n    (11,20),\n    (11,19),\n    (12, 17),\n    (13, 17),\n    (14, 17),\n    (14,20),\n    (13,20),\n    (14,18),\n    (14,19),\n    (11,17),\n    (11,18),\n    (6,20),\n    (9,20),\n]\ntime_variants_2 = [\n    (11.30,17.30), \n    (10,18),\n   (10.30, 18),\n    (10, 18.30),\n    (10.30, 18.30),\n    (11,18),\n    (11.30,18),\n    (11.30,18.30),\n    (11,18.30),\n    (11.30,19),\n    (11.30,19.30),\n    (11.30,16.30),\n    (11,15),\n]\n\n\n# Define the weather columns to be imputed (should match those added in add_weather_to_train)\nweather_cols = ['Weather_AirTemp', 'Weather_RH', 'Weather_WindSpd', 'Weather_WindDir', 'Weather_Solar']\n\n# Run the integrated processing function\nprocess_time_variants_and_impute_test(train_df, test_df, '/kaggle/input/ey-open-science-training-data/NY_Mesonet_Weather.xlsx', time_variants_1, weather_cols)\nprocess_time_variants_and_impute_test(train_df, test_df, '/kaggle/input/ey-open-science-training-data/NY_Mesonet_Weather.xlsx', time_variants_2, weather_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:42:35.733473Z","iopub.execute_input":"2025-03-03T10:42:35.733970Z","iopub.status.idle":"2025-03-03T10:45:43.642395Z","shell.execute_reply.started":"2025-03-03T10:42:35.733931Z","shell.execute_reply":"2025-03-03T10:45:43.641057Z"}},"outputs":[{"name":"stdout","text":"\nProcessing time variant with target window [11.3, 17.3)...\nSaved enhanced training data: train_enh_11.3_17.3.csv\nSaved imputed test data: test_imputed_11.3_17.3.csv\n\nProcessing time variant with target window [10, 18)...\nSaved enhanced training data: train_enh_10_18.csv\nSaved imputed test data: test_imputed_10_18.csv\n\nProcessing time variant with target window [10.3, 18)...\nSaved enhanced training data: train_enh_10.3_18.csv\nSaved imputed test data: test_imputed_10.3_18.csv\n\nProcessing time variant with target window [10, 18.3)...\nSaved enhanced training data: train_enh_10_18.3.csv\nSaved imputed test data: test_imputed_10_18.3.csv\n\nProcessing time variant with target window [10.3, 18.3)...\nSaved enhanced training data: train_enh_10.3_18.3.csv\nSaved imputed test data: test_imputed_10.3_18.3.csv\n\nProcessing time variant with target window [11, 18)...\nSaved enhanced training data: train_enh_11_18.csv\nSaved imputed test data: test_imputed_11_18.csv\n\nProcessing time variant with target window [11.3, 18)...\nSaved enhanced training data: train_enh_11.3_18.csv\nSaved imputed test data: test_imputed_11.3_18.csv\n\nProcessing time variant with target window [11.3, 18.3)...\nSaved enhanced training data: train_enh_11.3_18.3.csv\nSaved imputed test data: test_imputed_11.3_18.3.csv\n\nProcessing time variant with target window [11, 18.3)...\nSaved enhanced training data: train_enh_11_18.3.csv\nSaved imputed test data: test_imputed_11_18.3.csv\n\nProcessing time variant with target window [11.3, 19)...\nSaved enhanced training data: train_enh_11.3_19.csv\nSaved imputed test data: test_imputed_11.3_19.csv\n\nProcessing time variant with target window [11.3, 19.3)...\nSaved enhanced training data: train_enh_11.3_19.3.csv\nSaved imputed test data: test_imputed_11.3_19.3.csv\n\nProcessing time variant with target window [11.3, 16.3)...\nSaved enhanced training data: train_enh_11.3_16.3.csv\nSaved imputed test data: test_imputed_11.3_16.3.csv\n\nProcessing time variant with target window [11, 15)...\nSaved enhanced training data: train_enh_11_15.csv\nSaved imputed test data: test_imputed_11_15.csv\n","output_type":"stream"}],"execution_count":34},{"id":"0617e59d","cell_type":"markdown","source":"# imputing test with the help of train with spacial approximity","metadata":{"papermill":{"duration":0.012338,"end_time":"2025-02-07T22:31:47.034578","exception":false,"start_time":"2025-02-07T22:31:47.022240","status":"completed"},"tags":[]}},{"id":"876dc27c-7214-461c-a3db-b31733e295de","cell_type":"code","source":"# check_df = pd.read_csv('/kaggle/working/test_imputed_11.3_17.3.csv')\n# check_df.nunique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:45:43.643721Z","iopub.execute_input":"2025-03-03T10:45:43.644041Z","iopub.status.idle":"2025-03-03T10:45:43.658661Z","shell.execute_reply.started":"2025-03-03T10:45:43.643990Z","shell.execute_reply":"2025-03-03T10:45:43.657251Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"Longitude          1032\nLatitude           1030\nUHI Index             0\ngeometry           1040\nWeather_AirTemp       8\nWeather_RH           18\nWeather_WindSpd      16\nWeather_WindDir      22\nWeather_Solar        24\ndtype: int64"},"metadata":{}}],"execution_count":35},{"id":"acdaeedf","cell_type":"code","source":"# import geopandas as gpd\n# from shapely.geometry import Point\n# from sklearn.neighbors import NearestNeighbors\n\n# def df_to_gdf(df, lon_col = 'Longitude', lat_col = 'Latitude', crs = 'EPSG:4326'):\n#     geometry = [Point(xy) for xy in zip(df[lon_col], df[lat_col])]\n#     return gpd.GeoDataFrame(df, geometry=geometry, crs=crs)\n\n# def impute_weather_from_train(train_gdf, test_gdf, weather_cols):\n#     X_train = np.array(list(zip(train_gdf.geometry.x, train_gdf.geometry.y)))\n#     X_test = np.array(list(zip(test_gdf.geometry.x, test_gdf.geometry.y)))\n\n#     nbrs = NearestNeighbors(n_neighbors=1, algorithm='auto').fit(X_train)\n#     distances, indices = nbrs.kneighbors(X_test)\n\n#     for col in weather_cols:\n#         test_gdf[col] = train_gdf.iloc[indices.flatten()][col].values\n\n#     return test_gdf\n# # def impute_weather_from_train(train_gdf, test_gdf, weather_cols, k=3):\n# #     X_train = np.array(list(zip(train_gdf.geometry.x, train_gdf.geometry.y)))\n# #     X_test = np.array(list(zip(test_gdf.geometry.x, test_gdf.geometry.y)))\n\n# #     nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(X_train)\n# #     distances, indices = nbrs.kneighbors(X_test)\n\n# #     # Inverse distance weighting\n# #     weights = 1 / (distances + 1e-8)  # Adding small value to avoid division by zero\n# #     weights /= weights.sum(axis=1, keepdims=True)\n\n# #     for col in weather_cols:\n# #         imputed_values = np.sum(train_gdf.iloc[indices.flatten()][col].values.reshape(-1, k) * weights, axis=1)\n# #         test_gdf[col] = imputed_values\n\n# #     return test_gdf\n\n# train_gdf = df_to_gdf(train_enh_, lon_col='Longitude', lat_col='Latitude')\n# test_gdf = df_to_gdf(test_df, lon_col='Longitude', lat_col='Latitude')\n\n# train_gdf = train_gdf.to_crs('EPSG:2263')\n# test_gdf = test_gdf.to_crs('EPSG:2263')\n\n# # weather_cols = ['surface_air_temp', 'relative_humidity', 'avg_wind_speed', 'wind_direction', 'solar_flux']\n\n# test_6_20 = impute_weather_from_train(train_gdf, test_gdf, weather_cols)\n# test_gdf = test_gdf.to_crs('EPSG:4326')","metadata":{"papermill":{"duration":2.147477,"end_time":"2025-02-07T22:31:49.194712","exception":false,"start_time":"2025-02-07T22:31:47.047235","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:45:43.660115Z","iopub.execute_input":"2025-03-03T10:45:43.660605Z","iopub.status.idle":"2025-03-03T10:45:43.666689Z","shell.execute_reply.started":"2025-03-03T10:45:43.660558Z","shell.execute_reply":"2025-03-03T10:45:43.665334Z"}},"outputs":[],"execution_count":36},{"id":"164b89ee","cell_type":"code","source":"# input_cols = [col for col in train_enh.columns if col!='Longitude' and col!='Latitude' and col!='UHI Index' and col!='geometry' and col!='datetime' and col!='time' and col!='borough' and col!='station']\n# input_cols","metadata":{"papermill":{"duration":0.019369,"end_time":"2025-02-07T22:31:49.226224","exception":false,"start_time":"2025-02-07T22:31:49.206855","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:45:43.667835Z","iopub.execute_input":"2025-03-03T10:45:43.668198Z","iopub.status.idle":"2025-03-03T10:45:43.693531Z","shell.execute_reply.started":"2025-03-03T10:45:43.668159Z","shell.execute_reply":"2025-03-03T10:45:43.692080Z"}},"outputs":[],"execution_count":37},{"id":"83da751e","cell_type":"code","source":"# # weather_cols = [\n# #     \"Weather_AirTemp\", \"Weather_RH\", \"Weather_WindSpd\",\n# #     \"Weather_WindDir\", \"Weather_Solar\", 'THI', 'Temp_Solar_Interaction',\n# #     'Wind_Temp_Interaction', 'Humidity_Solar_Interaction'\n# # ]\n# # def new_features(df):\n# #     df['THI'] = df['Weather_AirTemp'] - (0.55 * (1 - df['Weather_RH'] / 100) * (df['Weather_AirTemp'] - 14.5))\n# #     df['Temp_Solar_Interaction'] = df['Weather_AirTemp'] * df['Weather_Solar']\n# #     df['Wind_Temp_Interaction'] = df['Weather_WindSpd'] * df['Weather_AirTemp']\n# #     df['Humidity_Solar_Interaction'] = df['Weather_RH'] * df['Weather_Solar']\n# #     return df\n\n# train_weather = train_enh[input_cols]\n# test_weather = test_gdf[input_cols]\n# train_weather.to_csv('train_weather.csv', index=False)\n# test_weather.to_csv('test_weather.csv', index=False)","metadata":{"papermill":{"duration":0.050446,"end_time":"2025-02-07T22:31:49.288973","exception":false,"start_time":"2025-02-07T22:31:49.238527","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:45:43.694661Z","iopub.execute_input":"2025-03-03T10:45:43.695003Z","iopub.status.idle":"2025-03-03T10:45:43.716110Z","shell.execute_reply.started":"2025-03-03T10:45:43.694974Z","shell.execute_reply":"2025-03-03T10:45:43.714904Z"}},"outputs":[],"execution_count":38},{"id":"d0ac5c05","cell_type":"code","source":"# test_gdf.nunique()","metadata":{"papermill":{"duration":0.024781,"end_time":"2025-02-07T22:31:49.325891","exception":false,"start_time":"2025-02-07T22:31:49.301110","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:45:43.717811Z","iopub.execute_input":"2025-03-03T10:45:43.718236Z","iopub.status.idle":"2025-03-03T10:45:43.738973Z","shell.execute_reply.started":"2025-03-03T10:45:43.718189Z","shell.execute_reply":"2025-03-03T10:45:43.737829Z"}},"outputs":[],"execution_count":39},{"id":"0ab971fe-898b-4caa-bf8f-511e68b0b4b6","cell_type":"code","source":"# train = pd.read_csv('/kaggle/working/train_enh_12_17.csv')\n# test = pd.read_csv('/kaggle/working/test_imputed_12_17.csv')\n# train.drop(columns=['Longitude', 'Latitude', 'datetime', 'UHI Index', 'time'], inplace=True)\n# test.drop(columns=['Longitude', 'Latitude', 'UHI Index', 'geometry'], inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:45:43.740175Z","iopub.execute_input":"2025-03-03T10:45:43.740532Z","iopub.status.idle":"2025-03-03T10:45:43.761106Z","shell.execute_reply.started":"2025-03-03T10:45:43.740502Z","shell.execute_reply":"2025-03-03T10:45:43.759838Z"}},"outputs":[],"execution_count":40},{"id":"e6fe122d","cell_type":"code","source":"# import xgboost as xgb\n# import lightgbm as lgb\n# target = train_df['UHI Index']\n# train[weather_cols] = train[weather_cols].astype('float64')\n# test[weather_cols] = test[weather_cols].astype('float64')\n# model = xgb.XGBRegressor(enable_categorical=False)\n# model.fit(train_enh[weather_cols], target)","metadata":{"papermill":{"duration":2.788074,"end_time":"2025-02-07T22:31:52.126821","exception":false,"start_time":"2025-02-07T22:31:49.338747","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:45:43.762462Z","iopub.execute_input":"2025-03-03T10:45:43.763040Z","iopub.status.idle":"2025-03-03T10:45:43.779836Z","shell.execute_reply.started":"2025-03-03T10:45:43.762998Z","shell.execute_reply":"2025-03-03T10:45:43.778484Z"}},"outputs":[],"execution_count":41},{"id":"5e30cc74","cell_type":"code","source":"# preds = model.predict(test[weather_cols])\n# preds","metadata":{"papermill":{"duration":0.025752,"end_time":"2025-02-07T22:31:52.165520","exception":false,"start_time":"2025-02-07T22:31:52.139768","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:45:43.781029Z","iopub.execute_input":"2025-03-03T10:45:43.781422Z","iopub.status.idle":"2025-03-03T10:45:43.799032Z","shell.execute_reply.started":"2025-03-03T10:45:43.781381Z","shell.execute_reply":"2025-03-03T10:45:43.797881Z"}},"outputs":[],"execution_count":42},{"id":"955bba5a","cell_type":"code","source":"# subm_test = pd.read_csv('/kaggle/input/test-df-ey-open-science/Submission_template_UHI2025-v2.csv')\n# subm_test['UHI Index'] = preds\n# subm_test.to_csv('submission_weather.csv', index=False)","metadata":{"papermill":{"duration":0.02573,"end_time":"2025-02-07T22:31:52.203982","exception":false,"start_time":"2025-02-07T22:31:52.178252","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:45:43.800265Z","iopub.execute_input":"2025-03-03T10:45:43.800672Z","iopub.status.idle":"2025-03-03T10:45:43.818182Z","shell.execute_reply.started":"2025-03-03T10:45:43.800642Z","shell.execute_reply":"2025-03-03T10:45:43.817035Z"}},"outputs":[],"execution_count":43},{"id":"c48bd3a1","cell_type":"code","source":"# train_enh.columns","metadata":{"papermill":{"duration":0.020861,"end_time":"2025-02-07T22:31:52.237430","exception":false,"start_time":"2025-02-07T22:31:52.216569","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:45:43.819627Z","iopub.execute_input":"2025-03-03T10:45:43.820042Z","iopub.status.idle":"2025-03-03T10:45:43.840905Z","shell.execute_reply.started":"2025-03-03T10:45:43.819995Z","shell.execute_reply":"2025-03-03T10:45:43.839724Z"}},"outputs":[],"execution_count":44},{"id":"ea2b51bd","cell_type":"code","source":"# def filter_afternoon(df):\n#         return df[\n#             (df['Date / Time'].dt.hour==15) |\n#             (df['Date / Time'].dt.hour==16)\n#         ]\n# bronx_3pm = filter_afternoon(bronx).mean(numeric_only=True).to_frame().T\n# manhattan_3pm = filter_afternoon(manhattan).mean(numeric_only=True).to_frame().T\n# manhattan_3pm","metadata":{"papermill":{"duration":0.018325,"end_time":"2025-02-07T22:31:52.268646","exception":false,"start_time":"2025-02-07T22:31:52.250321","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:45:43.842059Z","iopub.execute_input":"2025-03-03T10:45:43.842448Z","iopub.status.idle":"2025-03-03T10:45:43.858846Z","shell.execute_reply.started":"2025-03-03T10:45:43.842410Z","shell.execute_reply":"2025-03-03T10:45:43.857580Z"}},"outputs":[],"execution_count":45},{"id":"a6ac9478","cell_type":"code","source":"# def process_weather_data(weather_path):\n#     bronx = pd.read_excel(weather_path, sheet_name='Bronx', parse_dates=['Date / Time'])\n#     manhattan = pd.read_excel(weather_path, sheet_name='Manhattan', parse_dates=['Date / Time'])\n\n#     def filter_afternoon(df):\n#         return df[\n#             (df['Date / Time'].dt.hour==15) |\n#             (df['Date / Time'].dt.hour==16)\n#         ]\n#     bronx_3pm = filter_afternoon(bronx).mean(numeric_only=True).to_frame().T\n#     manhattan_3pm = filter_afternoon(manhattan).mean(numeric_only=True).to_frame().T\n#     bronx_3pm['borough'] = \"Bronx\"\n#     manhattan_3pm['borough'] = 'Manhattan'\n\n#     weather_agg = pd.concat([bronx_3pm, manhattan_3pm], ignore_index=True)\n#     weather_agg.columns = [f'{col}_3pm' if col !='borough' else col for col in weather_agg.columns]\n#     return weather_agg","metadata":{"papermill":{"duration":0.018277,"end_time":"2025-02-07T22:31:52.299593","exception":false,"start_time":"2025-02-07T22:31:52.281316","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:45:43.860382Z","iopub.execute_input":"2025-03-03T10:45:43.860744Z","iopub.status.idle":"2025-03-03T10:45:43.877070Z","shell.execute_reply.started":"2025-03-03T10:45:43.860715Z","shell.execute_reply":"2025-03-03T10:45:43.875915Z"}},"outputs":[],"execution_count":46},{"id":"10dab648","cell_type":"code","source":"# from shapely.geometry import Point\n\n# def assign_borough(df, lon_col='Longitude', lat_col='Latitude'):\n#     df = df.copy()\n#     df['borough'] = 'Unknown'\n\n#     bronx_bbox = (\n#         (-73.9335 <= df[lon_col]) & (df[lon_col] <= -73.7654) *\n#         (40.7855 <= df[lat_col]) & (df[lat_col] <= 40.9155)\n#     )\n#     manhattan_bbox = (\n#         (-74.0500 <= df[lon_col]) & (df[lon_col] <= -73.9000) &\n#         (40.7000 <= df[lat_col]) & (df[lat_col] <= 40.8800)\n#     )\n\n#     df.loc[bronx_bbox, 'borough'] = 'Bronx'\n#     df.loc[manhattan_bbox, 'borough'] = \"Manhattan\"\n#     return df","metadata":{"papermill":{"duration":0.01911,"end_time":"2025-02-07T22:31:52.331462","exception":false,"start_time":"2025-02-07T22:31:52.312352","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:45:43.878246Z","iopub.execute_input":"2025-03-03T10:45:43.878637Z","iopub.status.idle":"2025-03-03T10:45:43.895474Z","shell.execute_reply.started":"2025-03-03T10:45:43.878604Z","shell.execute_reply":"2025-03-03T10:45:43.894316Z"}},"outputs":[],"execution_count":47},{"id":"86d4f957","cell_type":"code","source":"# weather_agg = process_weather_data(weather_path)\n\n# train_wdf = assign_borough(train_df)\n# test_wdf = assign_borough(test_df)","metadata":{"papermill":{"duration":0.018762,"end_time":"2025-02-07T22:31:52.362834","exception":false,"start_time":"2025-02-07T22:31:52.344072","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:45:43.896552Z","iopub.execute_input":"2025-03-03T10:45:43.896858Z","iopub.status.idle":"2025-03-03T10:45:43.913950Z","shell.execute_reply.started":"2025-03-03T10:45:43.896832Z","shell.execute_reply":"2025-03-03T10:45:43.912581Z"}},"outputs":[],"execution_count":48},{"id":"da89728d","cell_type":"code","source":"# train_merged = pd.merge(train_wdf, weather_agg, on='borough', how='left')\n# test_merged = pd.merge(test_wdf, weather_agg, on='borough', how='left')","metadata":{"papermill":{"duration":0.018414,"end_time":"2025-02-07T22:31:52.393966","exception":false,"start_time":"2025-02-07T22:31:52.375552","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:45:43.915050Z","iopub.execute_input":"2025-03-03T10:45:43.915457Z","iopub.status.idle":"2025-03-03T10:45:43.937563Z","shell.execute_reply.started":"2025-03-03T10:45:43.915418Z","shell.execute_reply":"2025-03-03T10:45:43.936303Z"}},"outputs":[],"execution_count":49},{"id":"6ded742a","cell_type":"code","source":"# input_cols = ['Air Temp at Surface [degC]_3pm', 'Relative Humidity [percent]_3pm',\n#        'Avg Wind Speed [m/s]_3pm', 'Wind Direction [degrees]_3pm',\n#        'Solar Flux [W/m^2]_3pm']","metadata":{"papermill":{"duration":0.018362,"end_time":"2025-02-07T22:31:52.425121","exception":false,"start_time":"2025-02-07T22:31:52.406759","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:45:43.938744Z","iopub.execute_input":"2025-03-03T10:45:43.939131Z","iopub.status.idle":"2025-03-03T10:45:43.954329Z","shell.execute_reply.started":"2025-03-03T10:45:43.939094Z","shell.execute_reply":"2025-03-03T10:45:43.953230Z"}},"outputs":[],"execution_count":50},{"id":"d24a44f4","cell_type":"code","source":"# # train_merged[input_cols].rename(columns={'Air Temp at Surface [degC]_3pm':'air_temp', 'Relative Humidity [percent]_3pm':'relative_humitdiy',\n# #        'Avg Wind Speed [m/s]_3pm':'Avg_Wind_Speed', 'Wind Direction [degrees]_3pm':'wind_direction',\n# #        'Solar Flux [W/m^2]_3pm':'Solar_Flux'}, inplace=True)\n# train_merged[input_cols].rename(str, axis='columns', inplace=True)","metadata":{"papermill":{"duration":0.018732,"end_time":"2025-02-07T22:31:52.456564","exception":false,"start_time":"2025-02-07T22:31:52.437832","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:45:43.955510Z","iopub.execute_input":"2025-03-03T10:45:43.955806Z","iopub.status.idle":"2025-03-03T10:45:43.974560Z","shell.execute_reply.started":"2025-03-03T10:45:43.955783Z","shell.execute_reply":"2025-03-03T10:45:43.973529Z"}},"outputs":[],"execution_count":51},{"id":"7a78e495","cell_type":"code","source":"# train_merged[input_cols] = train_merged[input_cols].astype('float64')\n# test_merged[input_cols] = test_merged[input_cols].astype('float64')","metadata":{"papermill":{"duration":0.019013,"end_time":"2025-02-07T22:31:52.488242","exception":false,"start_time":"2025-02-07T22:31:52.469229","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:45:43.975418Z","iopub.execute_input":"2025-03-03T10:45:43.975701Z","iopub.status.idle":"2025-03-03T10:45:43.996617Z","shell.execute_reply.started":"2025-03-03T10:45:43.975679Z","shell.execute_reply":"2025-03-03T10:45:43.995475Z"}},"outputs":[],"execution_count":52},{"id":"65ecb78f","cell_type":"code","source":"# import xgboost as xgb\n# train_merged.columns = train_merged.columns.str.replace(r'[\\[\\]<>]', '', regex=True)\n# test_merged.columns = test_merged.columns.str.replace(r'[\\[\\]<>]', '', regex=True)\n# # Prepare features and target\n# input_cols = [col for col in train_merged.columns if col != 'UHI Index' and col != 'Latitude' and col!= 'Longitude' and col != 'datetime' and col!= 'time' and  col !='borough']\n# print(input_cols)\n# train_merged[input_cols] = train_merged[input_cols].astype('category')\n# test_merged[input_cols] = test_merged[input_cols].astype('category')\n# model = xgb.XGBRegressor()\n# model.fit(train_merged[input_cols], target)","metadata":{"papermill":{"duration":0.017786,"end_time":"2025-02-07T22:31:52.518869","exception":false,"start_time":"2025-02-07T22:31:52.501083","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:45:43.997681Z","iopub.execute_input":"2025-03-03T10:45:43.998298Z","iopub.status.idle":"2025-03-03T10:45:44.016305Z","shell.execute_reply.started":"2025-03-03T10:45:43.998257Z","shell.execute_reply":"2025-03-03T10:45:44.015041Z"}},"outputs":[],"execution_count":53}]}
